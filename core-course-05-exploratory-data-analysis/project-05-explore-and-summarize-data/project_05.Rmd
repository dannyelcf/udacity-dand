---
output: github_document
---
EDA in an Issue Tracking System Data Set
================================================================================
*by Dannyel Cardoso da Fonseca* 

```{r include=FALSE, "Global Set Up"}
# Cleaning the environment before start
# This is useful when execute "Restart R and Run All Chuncks"
rm(list = ls())

Sys.setlocale("LC_TIME","en_US.UTF-8")

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.path = "project_05_files/plots/", fig.retina = 3,
                      fig.height = 3.5, out.width = "86%")
```

```{r results="hide", "Load Packages"}
source("project_05.R")
load_packages(c("ggplot2", 
               "dplyr", 
               "lubridate", 
               "grid", 
               "gridExtra"))
```

```{r "Project Set Up"}
# NOTE: To run this notebook set up current work directory to this file location

# Set up default theme for plots
theme_set(theme_classic() %+replace%
            theme(panel.grid.major.y = element_line(size=.05, color="gray"),
                  plot.margin = unit(c(.3, 0, .5, 2), "cm"),
                  axis.text = element_text(size = rel(0.7), colour = "grey30"),
                  axis.title.x = element_text(size = rel(0.9),
                                              margin = margin(t = 5.5),
                                              vjust = 1),
                  axis.title.y = element_text(size = rel(0.9),
                                              angle = 90,
                                              margin = margin(r = 5.5), 
                                              vjust = 1),
                  plot.subtitle = element_text(size = rel(0.8), 
                                               hjust = 0, vjust = 1, 
                                               margin = margin(b = 5.5 * 0.9))))
```

```{r "Load Data Set"}
dataset <- load_dataset("issues_tracking.csv")

issues <- 
  dataset %>%
    select(starts_with("issue_")) %>%
    distinct() %>% 
    as.data.frame()

logs <- 
  dataset %>%
    select(issue_id, starts_with("log_")) %>%
    filter(!is.na(log_creation_date)) %>% 
    as.data.frame()
```

This project aims to explore a data set containing `r nrow(dataset)` observations 
of issues tracking and their history logs. The data set represents 5 years of project 
management which aimed maintenance and customization of many integrated systems
([SIG](https://docs.info.ufrn.br)) for the academic, administrative and human 
resources management at the Universidade Federal de Goi√°s ([UFG](https://www.ufg.br)).

A proprietary issue tracking system ([SIGProject](https://sigproject.esig.com.br)) 
was used to manage activities of company ([ESIG](https://www.esig.com.br)) and 
client ([Cercomp](https://www.cercomp.ufg.br)) teams.

![Screenshot](project_05_files/screenshot-sigproject.esig.com.br-2018.02.25-11-25-48.png)

I used data wrangling techniques to export data from that and clean them. The 
final data set, used in this project, and its documentation can be accessed, 
respectively, in these links: 

- [Issues Data Set](issues_tracking.csv)
- [Issues Data Set Documentation](issues_tracking.Rdoc.txt)

The exported data set, the wrangling process scripts and an example of one issue 
tracking can be find in [data_wrangling](data_wrangling) folder. 

# Data Set Summaries

In this section, I perform a univariate exploration in the data set, by first 
examining the structure, followed by analysis of time-series variables and ending 
with the analysis categorical and range variables.

### Data Set Structure

The issues data set contains `r nrow(dataset)` rows and `r ncol(dataset)` 
variables. Of these 24 variables `r ncol(issues)` are about issue data and 
`r ncol(logs)-1` about issue's logs.

```{r "Structure of the Data Set"}
# Show the issues' dataframe structure
str(dataset, max.level=1, vec.len=1, nchar.max=50)
```

The number of distinct issues rows and issue's logs rows are 
`r nrow(issues)` and `r nrow(logs)` respectively. That is, the number of issues 
represents `r round(nrow(issues)*100/nrow(dataset))`% of the data set and the 
number of logs represents `r round(nrow(logs)*100/nrow(dataset))`% of it. The 
`r round((nrow(dataset)-nrow(logs))*100/nrow(dataset))`% of logs remaining 
(`r nrow(dataset)-nrow(logs)` rows) represents issues that do not have history 
logs. 

```{r}
plot_number_logs_per_issue <- function(df_number_logs_per_issue) {
  summ_number_logs_per_issue <- df_summary(df_number_logs_per_issue, score)
  
  plot_number_logs_per_issue <-
    df_number_logs_per_issue %>% 
      ggplot(aes(x = score)) +
        geom_histogram(binwidth = 1, color = "gray", alpha = .3, 
                       boundary = summ_number_logs_per_issue$min, 
                       closed = "left") +
        plot_x_summary(df_number_logs_per_issue, score) +
        scale_x_continuous(breaks = seq(0, 43, 2)) +
        scale_y_continuous(breaks = seq(0, 800, 100)) +
        labs(title = "Distribution of the Number of Logs per Issue",
             subtitle = subtitle(observations = nrow(df_number_logs_per_issue),
                                 df_summary = summ_number_logs_per_issue),
             x = "Number of logs per issue",
             y = "Frequency") 
  
  plot_number_logs_per_issue
}

df_number_logs_per_issue <- 
  dataset %>%
    select(issue_id, log_creation_date) %>%
    group_by(issue_id) %>% 
    summarise(score = sum(!is.na(log_creation_date)))
```

The distribution and the summaries of number of logs per issue are ploted in the
histogram below.

```{r "Distribution of the Number of Logs per Issue"}
plt_number_logs_per_issue <-
  df_number_logs_per_issue %>% 
    plot_number_logs_per_issue()

plt_number_logs_per_issue
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean 
and the black dotted line represent the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

``` {r}
amount_upper_outiler <- 
  round(
    nrow(subset(df_number_logs_per_issue, score > 12)) * 100
    / 
    nrow(df_number_logs_per_issue)
  )
```

Analysing the plot above, we can note that 90% of issues have up to 9 history 
logs, 75% of them have up to 6 history logs and 50% of issues have between 2 and 
6 logs, a narrow range. Despite the skewed shape of plot, the median and mean 
are very close. This means that the amount of ouliers (after 12 logs per issue) 
is low, approximately `r amount_upper_outiler`% of issues.

The representative narrow range of logs in an issue makes us think that there 
shoud be an activity flow pattern to resolve an issue. This flow pattern migth 
be observed in a commom sequence of log status. See more informations in the 
[Log Status](#log-status) section.

The next 4 sections show the analisys of the temporal variables: 
`issue_creation_date`, `issue_start_date`, `issue_deadline_date` and 
`issue_time_spent`. In an issue tracking system, temporal variables is the 
fundamental piece for monitoring and control of activities.

### Issue Creation Date

The data set analyzed comprises issues created in the period between 
`r format(min(issues$issue_creation_date), "%m/%d/%Y")` and 
`r format(max(issues$issue_creation_date), "%m/%d/%Y")`. More precisaly, between 
`r format(min(issues$issue_creation_date), "%H:%M:%S")` of 
`r format(min(issues$issue_creation_date), "%m/%d/%Y")` and 
`r format(max(issues$issue_creation_date), "%H:%M:%S")` of
`r format(max(issues$issue_creation_date), "%m/%d/%Y")`. 

```{r}
score_issue_created_by_month <- function(df_issue_created_by_month) {
  df_score_issue_created_by_month <- 
    df_issue_created_by_month %>% 
      group_by(issue_creation_date) %>% 
      summarise(score = n())
  
  df_score_issue_created_by_month
}

plot_score_issue_created_by_month <- function(df_issue_created_by_month) {
  df_score_issue_created_by_month <- 
    score_issue_created_by_month(df_issue_created_by_month)

  plot_score_issue_created_by_month <-
    df_score_issue_created_by_month %>% 
      ggplot(aes(x = issue_creation_date, y = score)) +
        geom_col(alpha = .3, color = "grey", width = 28) +
        plot_cumsummary(df_score_issue_created_by_month, 
                        x = issue_creation_date,
                        y = score) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.01, 0)) +
        scale_y_continuous(breaks = seq(0, 190, 15)) +
        labs(title = "Distribution of the Number of Issues Created per Month",
             subtitle = subtitle(nrow(df_issue_created_by_month)),
             x = "Issue creation date (per month)",
             y = "Frequency") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_score_issue_created_by_month
}

plot_cum_score_issue_created_by_month <- function(df_issue_created_by_month) {
  df_score_issue_created_by_month <- 
    score_issue_created_by_month(df_issue_created_by_month)
  
  df_cum_score_issue_created_by_month <- 
    df_score_issue_created_by_month %>%
      mutate(cumscore = cumsum(score))
  
  plot_cum_score_issue_created_by_month <-
    df_cum_score_issue_created_by_month %>% 
      ggplot(aes(x = issue_creation_date, y = cumscore)) +
        geom_area(alpha = .3, color = "grey") +
        geom_smooth(method = "lm") +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.02, 0)) +
        scale_y_continuous(breaks = seq(0, 4600, 500),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_created_by_month),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        coord_cartesian(ylim = c(0, 4600)) +
        labs(title = "Cumulative Number of Issues Created",
             subtitle = subtitle(nrow(df_issue_created_by_month)),
             x = "Issue creation date",
             y = "Number of issues") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_cum_score_issue_created_by_month
}

df_issue_created_by_month <- 
  issues %>% 
    filter(!is.na(issue_creation_date)) %>% 
    distinct(issue_id, 
             issue_creation_date = as.Date(floor_date(issue_creation_date,
                                                      "month")))
```

To get a sense of how it was the demand throughout the project see the plot 
below that shows the cumulative number of issues created along the project and 
the trend line (in blue).

```{r "Cumulative Number of Issues Created"}
plt_cum_score_issue_created_by_month <-
  df_issue_created_by_month %>% 
    plot_cum_score_issue_created_by_month()

plt_cum_score_issue_created_by_month
```

We note that the first 11 months (from May 2013 to March 2014) of the project 
had very low demand, approximately 5% of the total. Some reasons for this were:

- The customer and company teams were small;
- There were no defined work processes between customer and company;
- That was the first time that the customer outsourced the development and 
deployment of systems;
- The customer's team had no experience with systems being deployed and the 
company's team did not know the customer's day-to-day business deeply. 

The work processes and knowledge on both sides (customer and company) were 
being built over those 11 months. The teams grew in size and new modules started
development and deployment. The next 12 months (from April 2014 to March 2015) 
there was significant growth curve in the activities, approximately 25% of
growth over the previous 11 months. From June 2015 the activities growth seems 
to stabilize, sometimes taking small growth curves. In this period occurred 
approximately 65% of project activities. Besides, the trend line fitted with 
growth curve demonstrating that the project began to have a standardized 
behavior.

In the barplot below, we can see the project's behavior in another way. This
plot shows the distribution of the number of issues created per month and
their cumulative summaries.

```{r "Distribution of the Number of Issues Created per Month"}
plt_score_issue_created_by_month <- 
  df_issue_created_by_month %>% 
    plot_score_issue_created_by_month()

plt_score_issue_created_by_month
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
cumulated quartile, the black and red solid lines represent, respectivaly, 
cumulated median and mean.

Analysing the plot above, we note that the year 2013 had the lowest demand. The
cumulated mean variates between 10 and 20 issues per month. At the end of 2013 
and begin of 2014 there was a drop in activities because of the low administrative 
and academic activities at the university at the end of year. From April of 2014 
until February of 2015 there was significant growth in activities.
The cumulated mean increases from 10 to 70 issues per month. The accumulated mean
overcame the cumulated median and the distance between cumulated 3rd quartile 
and accumulated median became greater than distance between cumulated 1st 
quartile and cumulated median. This means that these months had a high number 
of issues created in relation to the past. 

But from August of 2015 the pace of growth dropped. Now, we can note that the 
distance between cumulated 1st quartile and cumulated median becomes greater 
than distance between cumulated 3rd quartile and cumulated median. This 
invertion provocated the overlap between cumulated mean and median. The 
stabilization of the growth also contributed to that. The average of growth pass 
to be only 10 monthly issues from February 2015. 

We also note that except the significant growth period (from April 2014 to 
February 2015) the months between September and December of each year had a 
decline in activities. The reason is the low administrative and academic 
activities at the university in this period. Thus, the demand for customization 
and maintenance of the systems decreases.

```{r}
plot_score_issue_created_by_wday <- function(df_issue_created_by_wday,
                                             subtitle_complement = NULL) {
  
  summ_issue_created_by_wday <- 
    df_issue_created_by_wday %>% 
      group_by(issue_creation_wday) %>% 
      summarise(frequency = n()) %>% 
      df_summary(frequency)
  
  df_score_issue_created_by_wday <- 
    df_issue_created_by_wday %>% 
      group_by(issue_creation_wday) %>% 
      summarise(score = n())
  
  plot_score_issue_created_by_wday <- 
    df_score_issue_created_by_wday %>% 
      ggplot(aes(x = issue_creation_wday, y = score)) +
        geom_col(color = "grey", alpha = .3) +
        plot_y_summary(df_issue_created_by_wday, issue_creation_wday) +
        scale_y_continuous(breaks = seq(0, 1020, 100),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_created_by_wday),
                             breaks = seq(0, 1, .02),
                             labels = scales::percent
                           )) +
        labs(title = "Frequency of Issues Created per Weekday",
             subtitle = subtitle(nrow(df_issue_created_by_wday),
                                 subtitle_complement,
                                 summ_issue_created_by_wday),
             x = "Weekday",
             y = "Frequency") 
  
  plot_score_issue_created_by_wday
}

df_issue_created_by_wday <- 
  issues %>% 
    filter(!is.na(issue_creation_date)) %>% 
    distinct(issue_id, 
             issue_creation_wday = wday(issue_creation_date, label = TRUE))
```

During the week, the demand for new activities were concentrated on business days 
(from Monday to Friday) as we can note in the barplot below.

```{r "Frequency of Issues Created per Weekday"}
plt_score_issue_created_by_wday <-
  df_issue_created_by_wday %>% 
    plot_score_issue_created_by_wday()

plt_score_issue_created_by_wday
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

Note that whether we sort business days by the frequency of issues creation we 
have Tue > Wed > Thu > Fri > Mon. Tuesday is the weekday that has more issues 
creation (mode). Monday and Friday are the business days with less issues 
creation.  One of the reasons for this is that, from April 2014, the work began 
to be planned by sprints. These sprints were planned every Tuesday morning and 
issues were created in the afternoon.

```{r}
df_issue_created_by_weekend <-
  df_issue_created_by_wday %>% 
    filter(issue_creation_wday == "Sat" | issue_creation_wday == "Sun")
```

Issues created on weenkend (`r nrow(df_issue_created_by_weekend)` issues) may be 
considered outliers. These are issues created on weekend shift that was done 
during the enrollment periods. Theses outliers pull the mean and 1st quartile 
down. Removing them, we have a new barplot. See the plot below.

```{r "Distribution of the Number of Issues Created per Weekday (No Weekend)"}
plt_score_issue_created_by_nowend <- 
  df_issue_created_by_wday %>% 
    filter(!(issue_creation_wday %in% 
               df_issue_created_by_weekend$issue_creation_wday)) %>% 
    plot_score_issue_created_by_wday("without the weekend")

plt_score_issue_created_by_nowend
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

Note that the summaries are now approximated. The median and mean overlap and 
the distance between 1st and 3rd quartile became narrow. These new summaries 
better reflect the behavior of issue creation.

```{r}
plot_issue_created_by_hour <- function(df_issue_created_by_hour,
                                       subtitle_complement = NULL) {
  
  summ_number_issue_created_by_hour <- df_summary(df_issue_created_by_hour, 
                                                  issue_creation_hour)
  
  plot_issue_created_by_hour <-
    df_issue_created_by_hour %>% 
      ggplot(aes(x = issue_creation_hour)) +
        geom_histogram(binwidth = 1, color = "gray", alpha = .3, 
                       boundary = summ_number_issue_created_by_hour$min, 
                       closed = "left") +
        plot_x_summary(df_issue_created_by_hour, issue_creation_hour) +
        scale_x_continuous(breaks = seq(0, 23, 1)) +
        scale_y_continuous(limits = c(0, 700), breaks = seq(0, 700, 100)) +
        labs(title = "Distribution of the Number of Issues Created per Hour of the Day",
             subtitle = subtitle(nrow(df_issue_created_by_hour),
                                 subtitle_complement,
                                 summ_number_issue_created_by_hour),
             x = "Hour of the day",
             y = "Frequency") 
  
  plot_issue_created_by_hour
}

df_issue_created_by_hour <- 
  issues %>% 
    filter(!is.na(issue_creation_date)) %>%
    distinct(issue_id, 
             issue_creation_hour = hour(issue_creation_date))
```

Analysing how was the behaviour of the issues creation per hour of the day we 
have the bimodal distribution below.

```{r "Distribution of the Number of Issues Created per Hour of the Day"}
plt_issue_created_by_hour <-
  df_issue_created_by_hour %>% 
    plot_issue_created_by_hour()

plt_issue_created_by_hour
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted lines represent the lower and upper threshold to the 
outliers (lower = 1st qu. - 1.5 IQR, upper = 3rd qu. + 1.5 IQR).

The high volume of issue creation comprises between 8:00h and 18:00h, office 
hours. The peak hours are around 10:00h and 15:00h. At lunch time, the demand 
for new issues decreases. We note that this bimodal distribution is quasi 
symmetrical. The 1st and 3rd quartiles match with modes and the median and mean 
differ by a few minutes.

Ploting this distribution again but with only office hours (from 8:00h to 18:00h) 
we have the same summaries of the distribution before. See the plot below.

```{r "Distribution of the Number of Issues Created per Hour of the Day (Only Office Hours)"}
plt_issue_created_by_office_hour <-
  df_issue_created_by_hour %>%
    filter(issue_creation_hour >= 8 & issue_creation_hour <= 18) %>% 
    plot_issue_created_by_hour("with only office hours")

plt_issue_created_by_office_hour
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

This shows us that the high issue creation volume actually comprises between 
8:00h and 18:00h.

### Issue Start Date

The behavior of the project in relation to the starting of a issue activity is 
similar to the behavior of its creation. The plots also are very similar. See 
below the comparison of their plots.

```{r}
score_issue_start_date_month <- function(df_issue_start_date_month) {
  df_score_issue_start_date_month <- 
    df_issue_start_date_month %>% 
      group_by(issue_start_date) %>% 
      summarise(score = n())
  
  df_score_issue_start_date_month
}

plot_score_issue_start_date_month <- function(df_issue_start_date_month) {
  df_score_issue_start_date_month <- 
    score_issue_start_date_month(df_issue_start_date_month)
  
  plot_score_issue_start_date_month <-   
    df_score_issue_start_date_month %>% 
      ggplot(aes(x = issue_start_date, y = score)) +
        geom_col(alpha = .3, color = "grey", width = 28) +
        plot_cumsummary(df_score_issue_start_date_month, 
                        x = issue_start_date,
                        y = score) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.01, 0)) +
        scale_y_continuous(breaks = seq(0, 185, 15)) +
        labs(title = "Distribution of the Number of Issues Started per Month",
             subtitle = subtitle(nrow(df_issue_start_date_month)),
             x = "Issue start date (per month)",
             y = "Frequency") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_score_issue_start_date_month
}

plot_cum_score_issue_start_date_month <- function(df_issue_start_date_month) {
  df_score_issue_start_date_month <- 
    score_issue_start_date_month(df_issue_start_date_month)
  
  df_cum_score_issue_start_date_month <- 
    df_score_issue_start_date_month %>%
      mutate(cumscore = cumsum(score))
  
  plot_cum_score_issue_start_date_month <-
    df_cum_score_issue_start_date_month %>% 
      ggplot(aes(x = issue_start_date, y = cumscore)) +
        geom_area(alpha = .3, color = "grey") +
        geom_smooth(method = "lm") +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.02, 0)) +
        scale_y_continuous(breaks = seq(0, 4600, 500),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_start_date_month),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        coord_cartesian(ylim = c(0, 4600)) +
        labs(title = "Cumulative Number of Issues Started",
             subtitle = subtitle(nrow(df_issue_start_date_month)),
             x = "Issue start date",
             y = "Number of issues") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_cum_score_issue_start_date_month
}

plot_score_issue_start_wday <- function(df_issue_start_wday,
                                        subtitle_complement = NULL) { 
  summ_issue_start_wday <- 
    df_issue_start_wday %>% 
      group_by(issue_start_wday) %>% 
      summarise(frequency = n()) %>% 
      df_summary(frequency)
  
  df_score_issue_start_wday <- 
    df_issue_start_wday %>% 
      group_by(issue_start_wday) %>% 
      summarise(score = n())

  plot_score_issue_start_wday <- 
    df_score_issue_start_wday %>% 
      ggplot(aes(x = issue_start_wday, y = score)) +
        geom_col(color = "grey", alpha = .3) +
        plot_y_summary(df_issue_start_wday, issue_start_wday) +
        scale_y_continuous(breaks = seq(0, 1020, 100),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_start_wday),
                             breaks = seq(0, 1, .02),
                             labels = scales::percent
                           )) +
        labs(title = "Frequency of Issues Started per Weekday",
             subtitle = subtitle(nrow(df_issue_start_wday),
                                 subtitle_complement,
                                 summ_issue_start_wday),
             x = "Weekday",
             y = "Frequency") 
  
  plot_score_issue_start_wday
}

df_issue_start_date_month <- 
  issues %>% 
    filter(!is.na(issue_start_date)) %>% 
    distinct(issue_id, 
             issue_start_date = as.Date(floor_date(issue_start_date,
                                                   "month")))

df_issue_start_wday <- 
  issues %>% 
    filter(!is.na(issue_start_date)) %>% 
    distinct(issue_id, 
             issue_start_wday = wday(issue_start_date, label = TRUE))
```

Comparison between cumulative number of issues created and started.

```{r fig.height=5.5, "Comparison between Cumulative Number of Issues Created and Started"} 
plt_cum_score_issue_start_date_month <-
  df_issue_start_date_month %>% 
    plot_cum_score_issue_start_date_month()

grid.arrange(plt_cum_score_issue_created_by_month + 
               scale_y_continuous(breaks = seq(0, 4600, 750)), 
             plt_cum_score_issue_start_date_month + 
               scale_y_continuous(breaks = seq(0, 4600, 750)),
             ncol = 1)
```

Comparison between distribution of the number of issues created and started per 
month.

```{r fig.height=5.5, "Comparison between Distribution of the Number of Issues Created and Started per Month"} 
plt_score_issue_start_date_month <-
  df_issue_start_date_month %>% 
    plot_score_issue_start_date_month()

grid.arrange(plt_score_issue_created_by_month + 
               scale_y_continuous(breaks = seq(0, 200, 50)), 
             plt_score_issue_start_date_month + 
               scale_y_continuous(breaks = seq(0, 200, 50)),
             ncol = 1)

```

Comparison between distribution of the number of issues created and started per 
weekday.

```{r fig.height=5.5, "Comparison between Distribution of the Number of Issues Created and Started per Weekday"}
plt_score_issue_start_wday <-
  df_issue_start_wday %>% 
    plot_score_issue_start_wday()


grid.arrange(plt_score_issue_created_by_wday + 
               scale_y_continuous(breaks = seq(0, 1020, 200)), 
             plt_score_issue_start_wday + 
               scale_y_continuous(breaks = seq(0, 1020, 200)),
             ncol = 1)
```

Comparison between distribution of the number of issues created and started per 
business day.

```{r fig.height=5.5, "Comparison between Distribution of the Number of Issues Created and Started per Weekday (No Weekend)"}
df_issue_start_weekend <-
  df_issue_start_wday %>% 
    filter(issue_start_wday == "Sat" | issue_start_wday == "Sun")

plt_score_issue_start_nowend <- 
  df_issue_start_wday %>% 
    filter(!(issue_start_wday %in% 
               df_issue_start_weekend$issue_start_wday)) %>% 
    plot_score_issue_start_wday("without the weekend")

grid.arrange(plt_score_issue_created_by_nowend + 
               scale_y_continuous(breaks = seq(0, 1020, 200)), 
             plt_score_issue_start_nowend + 
               scale_y_continuous(breaks = seq(0, 1020, 200)),
             ncol = 1)
```

The differences are practically that creation date has time information while 
start date does not have and there are more observation of creation date than 
start date.

```{r}
plot_issue_delay_start <- function(df_issue_delay_start) {
  summ_issue_delay_start <- df_summary(df_issue_delay_start, 
                                       issue_delay_start)
  
  plot_issue_delay_start <-
    df_issue_delay_start %>% 
      ggplot(aes(x = issue_delay_start)) +
        geom_histogram(binwidth = 5, color = "gray", alpha = .3, 
                       boundary = summ_issue_delay_start$min, 
                       closed = "left") +
        plot_x_summary(df_issue_delay_start, issue_delay_start) +
        scale_x_continuous(breaks = seq(0, 500, 5)) +
        scale_y_continuous(limits = c(0, 4000), breaks = seq(0, 4000, 300)) +
        coord_cartesian(xlim = c(0, 70)) +
        labs(title = "Distribution of the Number of Calendar Days to Start an Issue",
             subtitle = subtitle(nrow(df_issue_delay_start),
                                 df_summary = summ_issue_delay_start),
             x = "Number of calendar days",
             y = "Frequency") 
  
  plot_issue_delay_start
}

df_issue_delay_start <-
  issues %>% 
    select(issue_id, issue_creation_date, issue_start_date) %>% 
    filter(!is.na(issue_start_date)) %>% 
    mutate(issue_creation_date = as.Date(floor_date(issue_creation_date,
                                                    unit = "day"))) %>% 
    mutate(issue_delay_start = difftime(issue_start_date,
                                        issue_creation_date,
                                        units = "days")) %>% 
    # mutate(issue_delay_start = issue_delay_start - 
    #                            count_weekend_days(issue_start_date,
    #                                               issue_creation_date)) %>% 
    filter(issue_delay_start >= 0)

```

This similarity in the behavior of these two variables induces us to believe 
that there was not a big delay between the creation and the starting of a issue.
In fact, it can be seen in the plot below.

```{r "Distribution of the Number of Calendar Days to Start an Issue"}
df_issue_delay_start %>% 
  plot_issue_delay_start()
```

```{r}
percent_delay_lte_5_days <- 
  round(
    nrow(subset(df_issue_delay_start, 
                issue_delay_start >=0 & issue_delay_start <= 5)) * 100
    /
    nrow(df_issue_delay_start)
  )
```

About `r percent_delay_lte_5_days`% of `r nrow(df_issue_delay_start)` issues, 
with start date information, have less than or equal 5 calendar days of delay 
to start and 90% of them have less than or equal 16 calendar days. These days 
are insignificant in the overall view of project behavior.

### Issue Deadline Date

```{r}
na_deadline_date <- 
  round(
    nrow(subset(issues, is.na(issue_deadline_date))) * 100
    / 
    nrow(issues)
  )
```

Issue deadline date represents the planning date to deliver the issue. It seems 
to follow the same behaviour that issue creation date and issues start date but 
it has some peculiarities, starting by `NA` values. Issue deadline date has more 
`NA` values than those, approximately `r na_deadline_date`% of the number of 
issues. 

Its cumulative number of issues deadling is also a bit different from the others 
cumulative plots. See the plot below.

```{r}
score_issue_deadline_date_month <- function(df_issue_deadline_date_month) {
  df_score_issue_deadline_date_month <- 
    df_issue_deadline_date_month %>% 
      group_by(issue_deadline_date) %>% 
      summarise(score = n())
  
  df_score_issue_deadline_date_month
}

plot_score_issue_deadline_date_month <- function(df_issue_deadline_date_month) {
  df_score_issue_deadline_date_month <- 
    score_issue_deadline_date_month(df_issue_deadline_date_month)
    
  plot_score_issue_deadline_date_month <- 
    df_score_issue_deadline_date_month %>% 
      ggplot(aes(x = issue_deadline_date, y = score)) +
        geom_col(alpha = .3, color = "grey", width = 28) +
        plot_cumsummary(df_score_issue_deadline_date_month, 
                        x = issue_deadline_date,
                        y = score) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.01, 0)) +
        scale_y_continuous(breaks = seq(0, 80, 5)) +
        labs(title = "Distribution of the Number of Issues Deadline per Month",
             subtitle = subtitle(nrow(df_issue_deadline_date_month)),
             x = "Issue deadline date (per month)",
             y = "Frequency") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1))
  
  plot_score_issue_deadline_date_month
}

plot_cum_score_issue_deadline_date_month <- function(df_issue_deadline_date_month) {
  df_score_issue_deadline_date_month <- 
    score_issue_deadline_date_month(df_issue_deadline_date_month)
  
  df_cum_score_issue_deadline_date_month <- 
    df_score_issue_deadline_date_month %>%
      mutate(cumscore = cumsum(score))
  
  plot_cum_score_issue_deadline_date_month <-
    df_cum_score_issue_deadline_date_month %>% 
      ggplot(aes(x = issue_deadline_date, y = cumscore)) +
        geom_area(alpha = .3, color = "grey") +
        geom_smooth(method = "lm") +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.02, 0)) +
        scale_y_continuous(breaks = seq(0, 1600, 200),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_deadline_date_month),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        coord_cartesian(ylim = c(0, 1600)) +
        labs(title = "Cumulative Number of Issues Deadline",
             subtitle = subtitle(nrow(df_issue_deadline_date_month)),
             x = "Issue deadline date",
             y = "Number of issues") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_cum_score_issue_deadline_date_month
}

df_issue_deadline_date_month <- 
  issues %>% 
    filter(!is.na(issue_deadline_date)) %>% 
    distinct(issue_id, 
             issue_deadline_date = as.Date(floor_date(issue_deadline_date,
                                                      "month")))
```

```{r "Cumulative Number of Issues Deadline"}
plt_cum_score_issue_deadline_date_month <- 
  df_issue_deadline_date_month %>% 
    plot_cum_score_issue_deadline_date_month()

plt_cum_score_issue_deadline_date_month
```

We note that trend line does not fit perfectly with growth curve. There is a 
drop in the end of growth curve.

```{r}
df_issue_deadline_size <-
  issues %>% 
    select(issue_id, issue_creation_date, issue_start_date, issue_deadline_date) %>% 
    filter(!is.na(issue_deadline_date)) %>% 
    mutate(issue_creation_date = as.Date(floor_date(issue_creation_date,
                                                    unit = "day"))) %>%
    mutate(from_creation_to_deadline = difftime(issue_deadline_date,
                                                issue_creation_date,
                                                units = "days")) %>% 
    mutate(from_start_to_deadline = difftime(issue_deadline_date,
                                             issue_start_date,
                                             units = "days")) %>% 
    filter(from_creation_to_deadline >= 0) %>% 
    arrange(desc(from_creation_to_deadline))

```

```{r "Distribution of the Number of Issues Deadline per Month"}
plt_score_issue_deadline_date_month <- 
  df_issue_deadline_date_month %>% 
    plot_score_issue_deadline_date_month()

plt_score_issue_deadline_date_month
```

```{r "Distribution of the Number of Issues Deadline per Weekday"}
df_issue_deadline_wday <- 
  issues %>% 
    filter(!is.na(issue_deadline_date)) %>% 
    distinct(issue_id, 
             issue_deadline_wday = wday(issue_deadline_date, label = TRUE))

summ_issue_deadline_wday <- 
  df_issue_deadline_wday %>% 
    group_by(issue_deadline_wday) %>% 
    summarise(frequency = n()) %>% 
    df_summary(frequency)

df_score_issue_deadline_wday <- 
  df_issue_deadline_wday %>% 
    group_by(issue_deadline_wday) %>% 
    summarise(score = n())

plot_score_issue_deadline_wday <- 
  df_score_issue_deadline_wday %>% 
    ggplot(aes(x = issue_deadline_wday, y = score)) +
      geom_col(color = "grey", alpha = .3) +
      plot_y_summary(df_issue_deadline_wday, issue_deadline_wday) +
      scale_y_continuous(breaks = seq(0, 500, 50),
                         sec.axis = sec_axis(
                           trans = ~. / nrow(df_issue_deadline_wday),
                           breaks = seq(0, 1, .02),
                           labels = scales::percent
                         )) +
      labs(title = "Frequency of Issues Deadline per Weekday",
           subtitle = subtitle(nrow(df_issue_deadline_wday)),
           x = "Weekday",
           y = "Frequency") 

print(rbind(y = summ_issue_deadline_wday))
print(plot_score_issue_deadline_wday)
```

### Issue First Delivery Date

### Issue Time Spent

```{r "Distribution of the Number of Time Spent in a Issue per Hour"}
df_issue_time_spent_hour <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, 
             issue_time_spent = (issue_time_spent / 3600))

summ_issue_time_spent_hour <- df_summary(df_issue_time_spent_hour, 
                                         issue_time_spent)

plot_issue_time_spent_hour <- 
  df_issue_time_spent_hour %>% 
    ggplot(aes(x = issue_time_spent)) +
      geom_histogram(binwidth = 1, color = "gray", alpha = .3, 
                     boundary = summ_issue_time_spent_hour$min, 
                     closed = "left") +
      plot_x_summary(df_issue_time_spent_hour, issue_time_spent) +
      scale_x_continuous(breaks = seq(0, 110, 5)) +
      scale_y_continuous(breaks = seq(0, 3000, 250)) +
      labs(title = "Distribution of the Number of Time Spent in a Issue per Hour",
           subtitle = subtitle(nrow(df_issue_time_spent_hour)),
           x = "Hours spent",
           y = "Frequency") 

print(rbind(x = summ_issue_time_spent_hour))
print(plot_issue_time_spent_hour)
```

```{r "Distribution of the Number of Time Spent in a Issue per Hour (Zoomed In)"}
plot_issue_time_spent_hour + 
  scale_x_continuous(breaks = seq(0, 24, 1)) +
  scale_y_continuous(breaks = seq(0, 2700, 200)) +
  coord_cartesian(xlim = c(0, 24)) +
  labs(subtitle = subtitle(nrow(df_issue_time_spent_hour), 
                           "zoomed in to the first 24 hours"))
```

```{r "Distribution of the Number of Time Spent in a Issue (Less Than 1 Hour)"}
df_issue_time_spent_min <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, issue_time_spent = (issue_time_spent / 60)) %>% 
    filter(issue_time_spent < 60)

summ_issue_time_spent_min <- df_summary(df_issue_time_spent_min, 
                                        issue_time_spent)

plot_issue_time_spent_min <- 
  df_issue_time_spent_min %>% 
    ggplot(aes(x = issue_time_spent)) +
      geom_histogram(binwidth = 5, color = "gray", alpha = .3, 
                     boundary = summ_issue_time_spent_min$min, 
                     closed = "left") +
      plot_x_summary(df_issue_time_spent_min, issue_time_spent) +
      scale_x_continuous(breaks = seq(0, 60, 5)) +
      scale_y_continuous(breaks = seq(0, 1700, 150)) +
      labs(title = "Distribution of the Number of Time Spent in a Issue",
           subtitle = subtitle(nrow(df_issue_time_spent_min), 
                             "less than 1 hour"),
           x = "Minutes spent",
           y = "Frequency")  

print(rbind(x = summ_issue_time_spent_min))
print(plot_issue_time_spent_min)
```

```{r "Head Issue Time Spent"}
df_issue_time_spent_min %>% 
  group_by(issue_time_spent) %>% 
  summarise(score = sum(!is.na(issue_time_spent))) %>% 
  arrange(desc(score)) %>% 
  head(5) %>% 
  as.data.frame()
```

```{r "Distribution of the Number of Time Spent in a Issue (Less Than 1 Hour and Non  0)"}
df_issue_time_spent_min <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, issue_time_spent = (issue_time_spent / 60)) %>% 
    filter(issue_time_spent != 0 & issue_time_spent < 60)

summ_issue_time_spent_min <- df_summary(df_issue_time_spent_min, 
                                         issue_time_spent)

plot_issue_time_spent_min <- 
  df_issue_time_spent_min %>% 
    ggplot(aes(x = issue_time_spent)) +
      geom_histogram(binwidth = 10, color = "gray", alpha = .3, 
                     boundary = summ_issue_time_spent_min$min, 
                     closed = "left") +
      plot_x_summary(df_issue_time_spent_min, issue_time_spent) +
      scale_x_continuous(breaks = seq(6, 60, 10)) +
      scale_y_continuous(breaks = seq(0, 500, 50)) +
      labs(title = "Distribution of the Number of Time Spent in a Issue",
           subtitle = subtitle(nrow(df_issue_time_spent_min), 
                             "less than 1 hour and non 0"),
           x = "Minutes spent",
           y = "Frequency") 

print(rbind(x = summ_issue_time_spent_min))
print(plot_issue_time_spent_min)
```

```{r "Distribution of the Number of Time Spent in a Issue (Non 0)"}
df_issue_time_spent_hour <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, 
             issue_time_spent = (issue_time_spent / 3600)) %>% 
    filter(issue_time_spent != 0)

summ_issue_time_spent_hour <- df_summary(df_issue_time_spent_hour, 
                                         issue_time_spent)

plot_issue_time_spent_hour <- 
  df_issue_time_spent_hour %>% 
    ggplot(aes(x = issue_time_spent)) +
      geom_histogram(binwidth = 1, color = "gray", alpha = .3, 
                     boundary = summ_issue_time_spent_hour$min, 
                     closed = "left") +
      plot_x_summary(df_issue_time_spent_hour, issue_time_spent) +
      scale_x_continuous(breaks = seq(0, 24, 1)) +
      scale_y_continuous(breaks = seq(0, 2700, 150)) +
      coord_cartesian(xlim = c(0, 24)) +
      labs(title = "Distribution of the Number of Time Spent in a Issue",
           subtitle = subtitle(nrow(df_issue_time_spent_hour), 
                               "non 0 zoomed in to the first 24 hours"),
           x = "Hours spent",
           y = "Frequency") 

print(rbind(x = summ_issue_time_spent_hour))
print(plot_issue_time_spent_hour)
```

### Issue Type

In the issue tracking system, 4 types of issues were used to classify the 
purpose of a issue. They are:

```{r "Issue Type Values"}
levels(issues$issue_type)
```

The frequency of issues created by each issue type is shown in the graph below.

```{r "Frequency of Issue Type"}
df_issue_type <- 
  issues %>% 
    filter(!is.na(issue_type)) %>% 
    distinct(issue_id, issue_type)

df_score_issue_type <- 
  df_issue_type %>% 
    group_by(issue_type) %>% 
    summarise(score = n())

plot_score_issue_type <- 
  df_score_issue_type %>% 
    ggplot(aes(x = reorder(issue_type, -score), y = score/sum(score))) +
      geom_col(color = "grey", alpha = .3) +
      add_label(df_score_issue_type$score) +
      scale_y_continuous(limits = c(0, .85), breaks = seq(0, 1, .1), 
                         labels = scales::percent) + 
      labs(title = "Frequency of Issue Type",
           subtitle = subtitle(nrow(df_issue_type)),
           x = "Issue type",
           y = "Frequency")  

plot_score_issue_type
```

Analysing the plot above, we note that most of the issues are of the MAINTENANCE 
type (around 75%). Next comes the issues of the CUSTOMIZATION type (around 20%). 
And, with less than 0.05% comes the issues of the types DATA MIGRATION and OTHERS.
Thus, we can summarize that project management was characterized by corrective 
maintenance activities of existing systems and subsystems.

The demand for adaptation and evolution of the systems was not insignificant. 
Although the amount of CUSTOMIZATION and DATA MIGRATION issues are less than 
MAINTENANCE, they may have indirectly influenced in the creation of large volume 
of MAINTENANCE issues. Maybe, CUSTOMIZATION issues had provocated related creation 
of MAINTENANCE issues. The same is true for DATA MIGRATION. An analysis of 
issues creation timeline by system/subsystem may answer that assumption.

### Issue System

```{r "Frequency of Issue System"}
df_issue_system <-
  issues %>% 
    filter(!is.na(issue_system)) %>% 
    distinct(issue_id, issue_system)

df_score_issue_system <- 
  df_issue_system %>% 
    group_by(issue_system) %>% 
    summarise(score = n())

plot_score_issue_system <- 
  df_score_issue_system %>% 
    ggplot(aes(x = reorder(issue_system, -score), y = score/sum(score))) +
      geom_col(color = "grey", alpha = .3) +
      add_label(df_score_issue_system$score) +
      scale_y_continuous(limits = c(0, .85), breaks = seq(0, 1, .1), 
                         labels = scales::percent) + 
      labs(title = "Frequency of Issue System",
           subtitle = subtitle(nrow(df_issue_system)),
           x = "Issue system",
           y = "Frequency") +
      theme(axis.text.x = element_text(angle = 20, hjust = 1)) 

plot_score_issue_system
```

### Issue Subsystem

```{r "Frequency of Issue Subsystem"}
df_issue_subsystem <-
  issues %>% 
    filter(!is.na(issue_subsystem)) %>% 
    distinct(issue_id, issue_system, issue_subsystem)

df_score_top15_issue_subsystem <- 
  df_issue_subsystem %>%
    group_by(issue_system, issue_subsystem) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) %>% 
    ungroup() %>% 
    filter(row_number() <= 15)

plot_score_top15_issue_subsystem <- 
  df_score_top15_issue_subsystem %>% 
    ggplot(aes(x = reorder(paste0("(", issue_system, ") ", issue_subsystem), 
                           -score), 
               y = score/sum(score))) +
      geom_col(color = "grey", alpha = .3) +
      add_label(df_score_top15_issue_subsystem$score) +
      scale_y_continuous(limits = c(0, .45), breaks = seq(0, 1, .1), 
                         labels = scales::percent) + 
      labs(title = "Frequency (Top 15) of Issue Subsystem",
           subtitle = subtitle(nrow(df_issue_subsystem)),
           x = "Issue subsystem",
           y = "Frequency") +
      theme(axis.text.x = element_text(angle = 25, hjust = 1)) 

plot_score_top15_issue_subsystem
```

### Issue Stakeholder

```{r "Frequency of Issue Stakeholder"}
df_issue_stakeholder <-
  issues %>% 
    filter(!is.na(issue_stakeholder)) %>% 
    distinct(issue_id, issue_stakeholder)

df_score_issue_stakeholder <- 
  df_issue_stakeholder %>% 
    group_by(issue_stakeholder) %>% 
    summarise(score = n())

plot_score_issue_stakeholder <- 
  df_score_issue_stakeholder %>% 
    ggplot(aes(x = reorder(issue_stakeholder, -score), y = score/sum(score))) +
      geom_col(color = "grey", alpha = .3) +
      add_label(df_score_issue_stakeholder$score) +
      scale_y_continuous(limits = c(0, .85), breaks = seq(0, 1, .1), 
                         labels = scales::percent) + 
      labs(title = "Frequency of Issue Stakeholder",
           subtitle = subtitle(nrow(df_issue_stakeholder)),
           x = "Issue stakeholder",
           y = "Frequency") 

plot_score_issue_stakeholder
```

### Issue Created By

```{r "Frequency of Issue Created By"}
df_issue_created_by <-
  issues %>% 
    filter(!is.na(issue_created_by)) %>% 
    distinct(issue_id, issue_stakeholder, issue_created_by)

df_score_top15_issue_created_by <- 
  df_issue_created_by %>%
    group_by(issue_stakeholder, issue_created_by) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) %>% 
    ungroup() %>% 
    filter(row_number() <= 15) %>% 
    mutate(issue_created_by = first_last_names(issue_created_by))

plot_score_top15_issue_created_by <- 
  df_score_top15_issue_created_by %>% 
    ggplot(aes(x = reorder(paste0("(", issue_stakeholder, ") ", issue_created_by), 
                           -score), 
               y = score/sum(score))) +
      geom_col(color = "grey", alpha = .3) +
      add_label(df_score_top15_issue_created_by$score) +
      scale_y_continuous(limits = c(0, .25), breaks = seq(0, 1, .05), 
                         labels = scales::percent) + 
      labs(title = "Frequency (Top 15) of Issue Created By",
           subtitle = subtitle(nrow(df_issue_created_by)),
           x = "Issue created by",
           y = "Frequency") +
      theme(axis.text.x = element_text(angle = 25, hjust = 1)) 

plot_score_top15_issue_created_by
```

### Issue Status

```{r "Frequency of Issue Status"}
df_issue_status <-
  issues %>% 
    filter(!is.na(issue_status)) %>%
    distinct(issue_id, issue_status)

df_score_issue_status <- 
  df_issue_status %>% 
    group_by(issue_status) %>% 
    summarise(score = n())

plot_score_issue_status <- 
  df_score_issue_status %>% 
    ggplot(aes(x = reorder(issue_status, -score), y = score/sum(score))) +
      geom_col(color = "grey", alpha = .3) +
      add_label(df_score_issue_status$score) +
      scale_y_continuous(limits = c(0, 1.1), breaks = seq(0, 1, .15), 
                         labels = scales::percent) + 
      labs(title = "Frequency of Issue Stakeholder",
           subtitle = subtitle(nrow(df_issue_status)),
           x = "Issue stakeholder",
           y = "Frequency") +
      theme(axis.text.x = element_text(angle = 20, hjust = 1)) 

plot_score_issue_status
```

### Issue Priority Number

```{r "Distribution of the Priority Number per Issue"}
df_issue_priority_number <- 
  issues %>% 
    filter(!is.na(issue_priority_number)) %>%
    distinct(issue_id, issue_priority_number)

summ_issue_priority_number <- df_summary(df_issue_priority_number, 
                                         issue_priority_number)

plot_issue_priority_number <- 
  df_issue_priority_number %>% 
    ggplot(aes(x = issue_priority_number)) +
      geom_histogram(binwidth = 50, color = "gray", alpha = .3, 
                     boundary = summ_issue_priority_number$min, 
                     closed = "left") +
      plot_x_summary(df_issue_priority_number, issue_priority_number) +
      scale_x_continuous(breaks = seq(0, 999, 50)) +
      scale_y_continuous(breaks = seq(0, 2700, 200)) +
      labs(title = "Distribution of the Priority Number per Issue",
           subtitle = subtitle(nrow(df_issue_priority_number),
                               df_summary = summ_issue_priority_number),
           x = "Issue priority number",
           y = "Frequency")

plot_issue_priority_number
```

```{r "Head Issue Priority Number"}
df_issue_priority_number %>% 
  group_by(issue_priority_number) %>% 
  summarise(score = sum(!is.na(issue_priority_number))) %>% 
  arrange(desc(score)) %>% 
  head(5) %>% 
  as.data.frame()
```

```{r "Distribution of the Priority Number per Issue (Dropped 999 and Zoomed In to 100)"}
df_issue_priority_number <- 
  issues %>% 
    filter(!is.na(issue_priority_number)) %>%
    distinct(issue_id, issue_priority_number) %>% 
    filter(issue_priority_number != 999)

summ_issue_priority_number <- df_summary(df_issue_priority_number, 
                                         issue_priority_number)

plot_issue_priority_number <- 
  df_issue_priority_number %>% 
    ggplot(aes(x = issue_priority_number)) +
      geom_histogram(binwidth = 10, color = "gray", alpha = .3, 
                     boundary = summ_issue_priority_number$min, 
                     closed = "left") +
      plot_x_summary(df_issue_priority_number, issue_priority_number) +
      scale_x_continuous(breaks = seq(0, 280, 10)) +
      scale_y_continuous(breaks = seq(0, 1600, 150)) +
      coord_cartesian(xlim = c(0, 100)) +
      labs(title = "Distribution of the Priority Number per Issue (Dropped 999)",
           subtitle = subtitle(nrow(df_issue_priority_number),
                               df_summary = summ_issue_priority_number),
           x = "Issue priority number",
           y = "Frequency") 

plot_issue_priority_number
```

```{r "Distribution of the Priority Number per Issue (Less than or Equal to 20)"}
df_issue_priority_number <- 
  issues %>% 
    filter(!is.na(issue_priority_number)) %>%
    distinct(issue_id, issue_priority_number) %>% 
    filter(issue_priority_number <= 20)

summ_issue_priority_number <- df_summary(df_issue_priority_number, 
                                         issue_priority_number)

plot_issue_priority_number <- 
  df_issue_priority_number %>% 
    ggplot(aes(x = issue_priority_number)) +
      geom_histogram(binwidth = 1, color = "gray", alpha = .3, 
                     boundary = summ_issue_priority_number$min, 
                     closed = "left") +
      plot_x_summary(df_issue_priority_number, issue_priority_number) +
      scale_x_continuous(breaks = seq(0, 20, 1)) +
      scale_y_continuous(breaks = seq(0, 450, 50)) +
      labs(title = "Distribution of the Priority Number per Issue (Less Than or Equal to 20)",
           subtitle = subtitle(nrow(df_issue_priority_number),
                               df_summary = summ_issue_priority_number),
           x = "Issue priority number",
           y = "Frequency") 

plot_issue_priority_number
```

### Issue Priority Scale

```{r "Frequency of Issue Priority Scale"}
df_issue_priority_scale <-
  issues %>% 
    filter(!is.na(issue_priority_scale)) %>%
    distinct(issue_id, issue_priority_scale)

df_score_issue_priority_scale <- 
  df_issue_priority_scale %>% 
    group_by(issue_priority_scale) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score))

plot_score_issue_priority_scale <- 
  df_score_issue_priority_scale %>% 
    ggplot(aes(x = issue_priority_scale, y = score/sum(score))) +
      geom_col(color = "grey", alpha = .3) +
      add_label(df_score_issue_priority_scale$score) +
      scale_y_continuous(limits = c(0, .7), breaks = seq(0, 1, .1), 
                         labels = scales::percent) + 
      labs(title = "Frequency of Issue Priority Scale",
           subtitle = subtitle(nrow(df_issue_priority_scale)),
           x = "Issue priority scale",
           y = "Frequency") 

plot_score_issue_priority_scale
```

### Issue Progress

```{r "Distribution of the Progress per Issue"}
df_issue_progress <- 
  issues %>% 
    filter(!is.na(issue_progress)) %>% 
    distinct(issue_id, issue_progress)

summ_issue_progress <- df_summary(df_issue_progress, 
                                  issue_progress)

plot_issue_progress <- 
  df_issue_progress %>% 
    ggplot(aes(x = issue_progress)) +
      geom_histogram(binwidth = 10, color = "gray", alpha = .3, 
                     boundary = summ_issue_progress$min, 
                     closed = "left") +
      plot_x_summary(df_issue_progress, issue_progress) +
      scale_x_continuous(breaks = seq(0, 100, 10)) +
      scale_y_continuous(breaks = seq(0, 4600, 500)) +
      labs(title = "Distribution of the Progress per Issue",
           subtitle = subtitle(nrow(df_issue_progress),
                               df_summary = summ_issue_progress),
           x = "Issue progress",
           y = "Frequency") 

plot_issue_progress
```

```{r "Head Issue Progress"}
df_issue_progress %>% 
  group_by(issue_progress) %>% 
  summarise(score = sum(!is.na(issue_progress))) %>% 
  arrange(desc(score)) %>% 
  head(5) %>% 
  as.data.frame()
```

### Log Build Info

```{r "Distribution of the Number of the Issues per System's Version"}
df_log_build_info <-
  logs %>% 
    filter(!is.na(log_build_info)) %>% 
    distinct(issue_id, log_build_info) %>% 
    group_by(log_build_info) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) 

summ_log_build_info <- df_summary(df_log_build_info, score)

plot_log_build_info <- 
  df_log_build_info %>% 
    ggplot(aes(x = score)) +
      geom_histogram(binwidth = 5, color = "gray", alpha = .3, 
                     boundary = summ_log_build_info$min, 
                     closed = "left") +
      plot_x_summary(df_log_build_info, score) +
      scale_x_continuous(breaks = seq(1, 125, 5)) +
      scale_y_continuous(breaks = seq(0, 320, 30)) +
      labs(title = "Distribution of the Number of the Issues per System's Version",
           subtitle = subtitle(nrow(df_log_build_info),
                               df_summary = summ_log_build_info),
           x = "Number of issues",
           y = "Frequency") 

plot_log_build_info
```

```{r "Distribution of the Number of the Issues per System's Version (Less Than 6 Issues)"}
df_log_build_info <- 
  logs %>% 
    filter(!is.na(log_build_info)) %>% 
    distinct(issue_id, log_build_info) %>% 
    group_by(log_build_info) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) %>% 
    filter(score < 6)

summ_log_build_info <- df_summary(df_log_build_info, score)

plot_log_build_info <- 
  df_log_build_info %>% 
    ggplot(aes(x = score)) +
      geom_histogram(binwidth = 1, color = "gray", alpha = .3, 
                     boundary = summ_log_build_info$min, 
                     closed = "left") +
      plot_x_summary(df_log_build_info, score) +
      scale_x_continuous(breaks = seq(1, 5, 1)) +
      scale_y_continuous(breaks = seq(0, 90, 10)) +
      labs(title = "Distribution of the Number of the Issues per System's Version",
           subtitle = subtitle(nrow(df_log_build_info),
                               df_summary = summ_log_build_info),
           x = "Number of issues",
           y = "Frequency") 

plot_log_build_info
```

### Log Status

> **Go back:** [Data Set Structure](#data-set-structure) 

### Reflections on Data Set Summaries

What is the commom flow of the log states? (Data Set Structure)

What makes the demand low in 2013?
What makes the demand grow rapidly in 2014?

