---
output: github_document
---
EDA in an Issue Tracking System Data Set
================================================================================
*by Dannyel Cardoso da Fonseca* 

```{r include=FALSE, "Global Set Up"}
# Cleaning the environment before start
# This is useful when execute "Restart R and Run All Chuncks"
rm(list = ls())

Sys.setlocale("LC_TIME","en_US.UTF-8")

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.path = "project_05_files/plots/", fig.retina = 3,
                      fig.height = 3.5, out.width = "86%")
```

```{r results="hide", "Load Packages"}
source("project_05.R")
load_packages(c("ggplot2", 
                "dplyr", 
                "lubridate"))
```

```{r "Project Set Up"}
# NOTE: To run this notebook set up current work directory to this file location

# Set up default theme for plots
theme_set(theme_classic() %+replace%
            theme(panel.grid.major.y = element_line(size=.05, color="grey50"),
                  plot.margin = unit(c(.3, 0, .5, 2), "cm"),
                  axis.text = element_text(size = rel(0.7), colour = "grey30"),
                  axis.title.x = element_text(size = rel(0.9),
                                              margin = margin(t = 5.5),
                                              vjust = 1),
                  axis.title.y = element_text(size = rel(0.9),
                                              angle = 90,
                                              margin = margin(r = 5.5), 
                                              vjust = 1),
                  plot.subtitle = element_text(size = rel(0.8), 
                                               hjust = 0, vjust = 1, 
                                               margin = margin(b = 5.5 * 0.9))))

DEFAULT_COLOR = "grey50"
DEFAULT_ALFA = .1
```

```{r "Load Data Set"}
dataset <- load_dataset("issues_tracking.csv")

issues <- 
  dataset %>%
    select(starts_with("issue_")) %>%
    distinct() %>% 
    as.data.frame()

logs <- 
  dataset %>%
    select(issue_id, starts_with("log_")) %>%
    filter(!is.na(log_creation_date)) %>% 
    as.data.frame()
```

This project aims to explore a data set containing `r nrow(dataset)` observations 
of issues tracking and their history logs. The data set represents 5 years of project 
management which aimed maintenance and customization of many integrated systems
([SIG](https://docs.info.ufrn.br)) for the academic, administrative and human 
resources management at the Universidade Federal de Goi√°s ([UFG](https://www.ufg.br)).

A proprietary issue tracking system ([SIGProject](https://sigproject.esig.com.br)) 
was used to manage activities of company ([ESIG](https://www.esig.com.br)) and 
client ([Cercomp](https://www.cercomp.ufg.br)) teams.

![Screenshot](project_05_files/screenshot-sigproject.esig.com.br-2018.02.25-11-25-48.png)

I used data wrangling techniques to export data from that and clean them. The 
final data set, used in this project, and its documentation can be accessed, 
respectively, in these links: 

- [Issues Data Set](issues_tracking.csv)
- [Issues Data Set Documentation](issues_tracking.Rdoc.txt)

The exported data set, the wrangling process scripts and an example of one issue 
tracking can be find in [data_wrangling](data_wrangling) folder. 

# Initial Descriptive Analysis

In this section, we perform a univariate exploration of the data set, first 
examining its structure, followed by the analysis of each variable starting with 
issue variables and ending with log variables. In each group (issue and log) I 
begin with exploration of temporal variables and end with the analysis of 
categorical and range variables.

### Data Set Structure

The issues data set contains `r nrow(dataset)` rows and `r ncol(dataset)` 
variables. Of these 24 variables `r ncol(issues)` are about issue data and 
`r ncol(logs)-1` about issue's logs.

```{r "Structure of the Data Set"}
# Show the issues' dataframe structure
glimpse(dataset)
```

The number of distinct issues rows and issue's logs rows are 
`r nrow(issues)` and `r nrow(logs)` respectively. That is, the number of issues 
represents `r round(nrow(issues)*100/nrow(dataset))`% of the data set and the 
number of logs represents `r round(nrow(logs)*100/nrow(dataset))`% of it. The 
`r round((nrow(dataset)-nrow(logs))*100/nrow(dataset))`% of logs remaining 
(`r nrow(dataset)-nrow(logs)` rows) represents issues that do not have history 
logs. 

```{r}
plot_number_logs_per_issue <- function(df_number_logs_per_issue) {
  summ_number_logs_per_issue <- df_summary(df_number_logs_per_issue, score)
  
  plot_number_logs_per_issue <-
    df_number_logs_per_issue %>% 
      ggplot(aes(x = score)) +
        geom_histogram(binwidth = 1, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                       boundary = summ_number_logs_per_issue$min, 
                       closed = "left") +
        plot_x_summary(df_number_logs_per_issue, score) +
        scale_x_continuous(breaks = seq(0, 43, 2)) +
        scale_y_continuous(breaks = seq(0, 800, 100)) +
        labs(title = "Distribution of the Number of Logs per Issue",
             subtitle = subtitle(observations = nrow(df_number_logs_per_issue),
                                 df_summary = summ_number_logs_per_issue),
             x = "Number of logs per issue",
             y = "Frequency") 
  
  plot_number_logs_per_issue
}

df_number_logs_per_issue <- 
  dataset %>%
    select(issue_id, log_creation_date) %>%
    group_by(issue_id) %>% 
    summarise(score = sum(!is.na(log_creation_date)))
```

The distribution and the summaries of number of logs per issue are ploted in the
histogram below.

```{r "Distribution of the Number of Logs per Issue"}
plt_number_logs_per_issue <-
  df_number_logs_per_issue %>% 
    plot_number_logs_per_issue()

plt_number_logs_per_issue
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted line represent the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

``` {r}
amount_upper_outiler <- 
  round(
    nrow(subset(df_number_logs_per_issue, score > 12)) * 100
    / 
    nrow(df_number_logs_per_issue)
  )
```

Analysing the plot above, we can note that most of issues have between 1 and 9 
history logs, approximately 1 standard deviation from the mean. Also, 75% of 
them have up to 6 history logs and 50% of issues have between 2 and 6 logs, a 
narrow range. Despite the skewed shape of plot, the median and mean are very 
close. This means that the amount of ouliers, after 12 logs per issue, is very 
low, approximately `r amount_upper_outiler`% of issues.

The representative narrow range of logs in an issue makes us think that there 
shoud be an activity flow pattern to resolve an issue. This flow pattern migth 
be observed in a commom sequence of log status. See more informations in the 
[Log Status](#log-status) section.

### Issue Creation Date

The data set analyzed comprises issues created in the period between 
`r format(min(issues$issue_creation_date), "%m/%d/%Y")` and 
`r format(max(issues$issue_creation_date), "%m/%d/%Y")`. More precisaly, between 
`r format(min(issues$issue_creation_date), "%H:%M:%S")` of 
`r format(min(issues$issue_creation_date), "%m/%d/%Y")` and 
`r format(max(issues$issue_creation_date), "%H:%M:%S")` of
`r format(max(issues$issue_creation_date), "%m/%d/%Y")`. 

```{r}
score_issue_created_by_month <- function(df_issue_created_by_month) {
  df_score_issue_created_by_month <- 
    df_issue_created_by_month %>% 
      group_by(issue_creation_date) %>% 
      summarise(score = n())
  
  df_score_issue_created_by_month
}

cum_score_issue_created_by_month <- function(df_issue_created_by_month) {
  df_score_issue_created_by_month <- 
    score_issue_created_by_month(df_issue_created_by_month)
  
  df_cum_score_issue_created_by_month <- 
    df_score_issue_created_by_month %>%
      mutate(cumscore = cumsum(score))
  
  df_cum_score_issue_created_by_month
}
```

```{r}
plot_cum_score_issue_created_by_month <- function(df_issue_created_by_month) {
  df_cum_score_issue_created_by_month <- 
    cum_score_issue_created_by_month(df_issue_created_by_month)
  
  plot_cum_score_issue_created_by_month <-
    df_cum_score_issue_created_by_month %>% 
      ggplot(aes(x = issue_creation_date, y = cumscore)) +
        geom_area(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        geom_point(color = DEFAULT_COLOR) +
        plot_year_vline() +
        geom_smooth(method = "lm", size = .5, fill = "blue", alpha = .2) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.02, 0)) +
        scale_y_continuous(breaks = seq(0, 4600, 500),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_created_by_month),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        coord_cartesian(ylim = c(0, 4600)) +
        labs(title = "Cumulative Number of Issues Created per Month",
             subtitle = subtitle(nrow(df_issue_created_by_month)),
             x = "Issue creation date (month)",
             y = "Number of issues") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_cum_score_issue_created_by_month
}

df_issue_created_by_month <- 
  issues %>% 
    filter(!is.na(issue_creation_date)) %>% 
    distinct(issue_id, 
             issue_creation_date = as.Date(floor_date(issue_creation_date,
                                                      "month")))
```

To get a sense of how it was the demand throughout the project see the plot 
below that shows the cumulative number of issues created per month along the 
project and its trend line.

```{r "Cumulative Number of Issues Created"}
plt_cum_score_issue_created_by_month <-
  df_issue_created_by_month %>% 
    plot_cum_score_issue_created_by_month()

plt_cum_score_issue_created_by_month
```

> **Note:** In the plot above, the blue solid line represents the trend of the 
data and dotted grey vertical lines represent the 1st day of year.

We note that the first 11 months (from May 2013 to March 2014) of the project 
had very low demand, approximately 4% of the total. Some reasons for this were:

- The customer and company teams were small;
- There were no defined work processes between customer and company;
- That was the first time that the customer outsourced the development and 
deployment of systems;
- The customer's team had no experience with systems being deployed and the 
company's team did not know the customer's day-to-day business deeply. 

The work processes and knowledge on both sides (customer and company) were 
being built over those 11 months. The teams grew in size and new modules started
development and deployment. The next 12 months (from April 2014 to March 2015) 
there was significant growth curve in the activities, approximately 25% of
growth over the previous 11 months. From June 2015 the activities growth seems 
to stabilize, sometimes taking small growth curves. In this period occurred 
approximately 65% of project activities. Besides, the trend line fitted with 
growth curve demonstrating that the project began to have a standardized 
behavior.

```{r}
plot_score_issue_created_by_month <- function(df_issue_created_by_month) {
  df_score_issue_created_by_month <- 
    score_issue_created_by_month(df_issue_created_by_month)

  plot_score_issue_created_by_month <-
    df_score_issue_created_by_month %>% 
      ggplot(aes(x = issue_creation_date, y = score)) +
        geom_area(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        geom_point(color = DEFAULT_COLOR) +
        plot_year_vline() +
        plot_cumsummary(df_score_issue_created_by_month, 
                        x = issue_creation_date,
                        y = score) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.01, 0)) +
        scale_y_continuous(breaks = seq(0, 195, 15)) +
        labs(title = "Distribution of the Number of Issues Created per Month",
             subtitle = subtitle(nrow(df_issue_created_by_month)),
             x = "Issue creation date (month)",
             y = "Frequency") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_score_issue_created_by_month
}
```

In the area plot below, we can see the project's behavior in another way. This
plot shows the distribution of the number of issues created per month and
their cumulative summaries.

```{r "Distribution of the Number of Issues Created per Month"}
plt_score_issue_created_by_month <- 
  df_issue_created_by_month %>% 
    plot_score_issue_created_by_month()

plt_score_issue_created_by_month
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
accumulated quartile, the black and red solid lines represent, respectivaly, 
accumulated median and mean and dotted grey vertical lines represent the 1st day 
of year.

Analysing the area plot above, we note that the year 2013 had the lowest demand. 
The accumulated mean variates around 15 issues per month. At the end of 2013 and 
begin of 2014 there was a drop in activities because of the low administrative 
and academic activities at the university at the end of year. 

From April of 2014 until February of 2015 there was significant growth in 
activities. The accumulated mean increases from 15 to 50 issues per month and it 
overcame the accumulated median. The distance between accumulated 3rd quartile 
and accumulated median became greater than distance between accumulated 1st 
quartile and accumulated median. All this indicates that these months had a high 
number of issues created in relation to the past. 

But from August of 2015 the pace of growth dropped. Now, we can note that the 
distance between accumulated 1st quartile and accumulated median becomes greater 
than distance between accumulated 3rd quartile and accumulated median. This 
invertion provocated the overlap between accumulated mean and median. The 
stabilization of the growth also contributed to that. The average of growth pass 
to be only 10 monthly issues (from 70 to 80), approximately. 

We also note that except the significant growth period (from April 2014 to 
February 2015) the months between September and December of each year had a 
decline in activities. The reason is the low administrative and academic 
activities at the university in this period. Thus, the demand for customization 
and maintenance of the systems decreases.

```{r}
plot_score_issue_created_by_wday <- function(df_issue_created_by_wday,
                                             subtitle_complement = NULL) {
  
  summ_issue_created_by_wday <- 
    df_issue_created_by_wday %>% 
      group_by(issue_creation_wday) %>% 
      summarise(frequency = n()) %>% 
      df_summary(frequency)
  
  df_score_issue_created_by_wday <- 
    df_issue_created_by_wday %>% 
      group_by(issue_creation_wday) %>% 
      summarise(score = n())
  
  plot_score_issue_created_by_wday <- 
    df_score_issue_created_by_wday %>% 
      ggplot(aes(x = issue_creation_wday, y = score)) +
        geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        plot_y_summary(df_issue_created_by_wday, issue_creation_wday) +
        scale_y_continuous(breaks = seq(0, 1020, 100),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_created_by_wday),
                             breaks = seq(0, 1, .02),
                             labels = scales::percent
                           )) +
        labs(title = "Frequency of Issues Created per Weekday",
             subtitle = subtitle(nrow(df_issue_created_by_wday),
                                 subtitle_complement,
                                 summ_issue_created_by_wday),
             x = "Weekday",
             y = "Frequency") 
  
  plot_score_issue_created_by_wday
}

df_issue_created_by_wday <- 
  issues %>% 
    filter(!is.na(issue_creation_date)) %>% 
    distinct(issue_id, 
             issue_creation_wday = wday(issue_creation_date, label = TRUE))
```

During the week, the demand for new activities were concentrated on business days 
(from Monday to Friday) as we can note in the barplot below.

```{r "Frequency of Issues Created per Weekday"}
plt_score_issue_created_by_wday <-
  df_issue_created_by_wday %>% 
    plot_score_issue_created_by_wday()

plt_score_issue_created_by_wday
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

Note that whether we sort business days by the frequency of issue creations we 
have Tue > Wed > Thu > Fri > Mon. Tuesday is the weekday that has more issues 
creation (mode). Monday and Friday are the business days with less issues 
creation.  One of the reasons for this is that, from April 2014, the work began 
to be planned by sprints. These sprints were planned every Tuesday morning and 
issues were created in the afternoon.

```{r}
df_issue_created_by_weekend <-
  df_issue_created_by_wday %>% 
    filter(issue_creation_wday == "Sat" | issue_creation_wday == "Sun")
```

Issues created on weenkend (`r nrow(df_issue_created_by_weekend)` issues) may be 
considered outliers. These are issues created on weekend shift that was done 
during the enrollment periods. Theses outliers pull the mean and 1st quartile 
down and increase the standard deviationof mean. Removing them, we have a new 
barplot. See it below.

```{r "Frequency of Issues Created per Weekday (No Weekend)"}
plt_score_issue_created_by_nowend <- 
  df_issue_created_by_wday %>% 
    filter(!(issue_creation_wday %in% 
               df_issue_created_by_weekend$issue_creation_wday)) %>% 
    plot_score_issue_created_by_wday("without the weekend")

plt_score_issue_created_by_nowend
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

Note that the summaries are now approximated. The median and mean overlap, the 
distance between 1st and 3rd quartile became narrow and the standard deviation 
of mean descrease. These new summaries better reflect the behavior of issue 
creation.

```{r}
plot_issue_created_by_hour <- function(df_issue_created_by_hour,
                                       subtitle_complement = NULL) {
  
  summ_number_issue_created_by_hour <- df_summary(df_issue_created_by_hour, 
                                                  issue_creation_hour)
  
  plot_issue_created_by_hour <-
    df_issue_created_by_hour %>% 
      ggplot(aes(x = issue_creation_hour)) +
        geom_histogram(binwidth = 1, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                       boundary = summ_number_issue_created_by_hour$min, 
                       closed = "left") +
        plot_x_summary(df_issue_created_by_hour, issue_creation_hour) +
        scale_x_continuous(breaks = seq(0, 23, 1)) +
        scale_y_continuous(limits = c(0, 700), breaks = seq(0, 700, 100)) +
        labs(title = "Distribution of the Number of Issues Created per Hour of the Day",
             subtitle = subtitle(nrow(df_issue_created_by_hour),
                                 subtitle_complement,
                                 summ_number_issue_created_by_hour),
             x = "Hour of the day",
             y = "Frequency") 
  
  plot_issue_created_by_hour
}

df_issue_created_by_hour <- 
  issues %>% 
    filter(!is.na(issue_creation_date)) %>%
    distinct(issue_id, 
             issue_creation_hour = hour(issue_creation_date))
```

Analysing how was the behaviour of the issue creations per hour of the day we 
have the bimodal distribution below.

```{r "Distribution of the Number of Issues Created per Hour of the Day"}
plt_issue_created_by_hour <-
  df_issue_created_by_hour %>% 
    plot_issue_created_by_hour()

plt_issue_created_by_hour
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean,
the black dotted lines represent the lower and upper threshold to the outliers 
(lower = 1st qu. - 1.5 IQR, upper = 3rd qu. + 1.5 IQR).

The high volume of issue creation comprises between 8:00h and 18:00h, office 
hours. The peak hours are around 10:00h and 15:00h. At lunch time, the demand 
for new issues decreases. We note that this bimodal distribution is quasi 
symmetrical. The 1st and 3rd quartiles match with modes and the median and mean 
differ by a few minutes.

Ploting this distribution again but with only office hours (from 8:00h to 18:00h) 
we have the same summaries of the distribution before. See the plot below.

```{r "Distribution of the Number of Issues Created per Hour of the Day (Only Office Hours)"}
plt_issue_created_by_office_hour <-
  df_issue_created_by_hour %>%
    filter(issue_creation_hour >= 8 & issue_creation_hour <= 18) %>% 
    plot_issue_created_by_hour("with only office hours")

plt_issue_created_by_office_hour
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

This shows us that the high issue creation volume actually comprises between 
8:00h and 18:00h.

### Issue Start Date

The behavior of the project in relation to the starting of a issue activity is 
similar to the behavior of its creation. The main differences are that the 
creation date has time information while start date does not have and there are 
more observation of creation date than start date.

```{r}
score_issue_start_date_month <- function(df_issue_start_date_month) {
  df_score_issue_start_date_month <- 
    df_issue_start_date_month %>% 
      group_by(issue_start_date) %>% 
      summarise(score = n())
  
  df_score_issue_start_date_month
}

cum_score_issue_start_date_month <- function(df_issue_start_date_month) {
  df_score_issue_start_date_month <- 
    score_issue_start_date_month(df_issue_start_date_month)
  
  df_cum_score_issue_start_date_month <- 
    df_score_issue_start_date_month %>%
      mutate(cumscore = cumsum(score))
  
  df_cum_score_issue_start_date_month
}
```

```{r}
plot_cum_score_issue_start_date_month <- function(df_issue_start_date_month) {
  df_cum_score_issue_start_date_month <- 
    cum_score_issue_start_date_month(df_issue_start_date_month)
  
  plot_cum_score_issue_start_date_month <-
    df_cum_score_issue_start_date_month %>% 
      ggplot(aes(x = issue_start_date, y = cumscore)) +
        geom_area(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        geom_point(color = DEFAULT_COLOR) +
        plot_year_vline() +
        geom_smooth(method = "lm", size = .5, fill = "blue", alpha = .2) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.02, 0)) +
        scale_y_continuous(breaks = seq(0, 4600, 500),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_start_date_month),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        coord_cartesian(ylim = c(0, 4600)) +
        labs(title = "Cumulative Number of Issues Started per Month",
             subtitle = subtitle(nrow(df_issue_start_date_month)),
             x = "Issue start date (month)",
             y = "Number of issues") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_cum_score_issue_start_date_month
}

df_issue_start_date_month <- 
  issues %>% 
    filter(!is.na(issue_start_date)) %>% 
    distinct(issue_id, 
             issue_start_date = as.Date(floor_date(issue_start_date,
                                                   "month")))
```

To show how is similar the behavior between creation and start issue date see 
the cumulative number of issues started along the project and its trend line in 
the plot below.

```{r "Cumulative Number of Issues Started per Month"} 
plt_cum_score_issue_start_date_month <-
  df_issue_start_date_month %>% 
    plot_cum_score_issue_start_date_month()

plt_cum_score_issue_start_date_month
```

> **Note:** In the plot above, the blue solid line represents the trend of the 
data and dotted grey vertical lines represent the 1st day of year.

Pratically it has the same shape and values of the Cumulative Number of Issues
Created per Month plot. 

This similarity induces us to believe that there was not a big delay between 
the creation and the starting of a issue. To verify this, I created a new 
variable named `issue_delay_start` which represents the delay, in calendar days, 
between creation of an issue and its start.

```{r}
issues$issue_delay_start <-
  issues %>% 
    select(issue_id, issue_creation_date, issue_start_date) %>% 
    mutate(issue_creation_date = as.Date(floor_date(issue_creation_date,
                                                    unit = "day"))) %>% 
    mutate(issue_delay_start = difftime(issue_start_date,
                                        issue_creation_date,
                                        units = "days")) %>% 
    pull(issue_delay_start) 
```

### Issue Delay Start

```{r}
plot_issue_delay_start <- function(df_issue_delay_start) {
  summ_issue_delay_start <- df_summary(df_issue_delay_start, 
                                       issue_delay_start)
  
  plot_issue_delay_start <-
    df_issue_delay_start %>% 
      ggplot(aes(x = issue_delay_start)) +
        geom_histogram(binwidth = 5, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                       boundary = summ_issue_delay_start$min, 
                       closed = "left") +
        plot_x_summary(df_issue_delay_start, issue_delay_start) +
        scale_x_continuous(breaks = seq(0, 500, 5)) +
        scale_y_continuous(limits = c(0, 4000), breaks = seq(0, 4000, 300)) +
        coord_cartesian(xlim = c(0, 70)) +
        labs(title = "Distribution of the Delay Between Creation and Start Date",
             subtitle = subtitle(nrow(df_issue_delay_start),
                                 df_summary = summ_issue_delay_start),
             x = "Number of calendar days",
             y = "Frequency") 
  
  plot_issue_delay_start
}

df_issue_delay_start <-
  issues %>% 
    select(issue_id, issue_delay_start) %>% 
    filter(!is.na(issue_delay_start)) %>% 
    filter(issue_delay_start >= 0)

```

See in the plot below the distribution of the delay between creation and start 
date.

```{r "Distribution of the Delay Between Creation and Start Date"}
plt_issue_delay_start <-
  df_issue_delay_start %>% 
    plot_issue_delay_start()

plt_issue_delay_start
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted lines represents the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

```{r}
percent_delay_lte_5_days <- 
  round(
    nrow(subset(df_issue_delay_start, 
                issue_delay_start >=0 & issue_delay_start <= 5)) * 100
    /
    nrow(df_issue_delay_start)
  )
```

About `r percent_delay_lte_5_days`% of `r nrow(df_issue_delay_start)` issues, 
with start date information, have less than or equal 5 calendar days of delay 
to start. These amount of days is very short compared to the 30 days of the 
month (granularity used in the plots). 

### Issue Deadline Date

```{r}
na_deadline_date <- 
  round(
    nrow(subset(issues, is.na(issue_deadline_date))) * 100
    / 
    nrow(issues)
  )
```

Issue deadline date represents the planning date to deliver the issue. It is 
planned at the beginning (start) of the activities to solution an issue.

It seems to follow the same behaviour that issue creation and start date but it 
has some particularities, starting by amount of `NA` values. Issue deadline date 
has more `NA` values than those, approximately `r na_deadline_date`% of the 
number of issues. 

Its cumulative plot is also a bit different from the others. See the plot below.

```{r}
score_issue_deadline_date_month <- function(df_issue_deadline_date_month) {
  df_score_issue_deadline_date_month <- 
    df_issue_deadline_date_month %>% 
      group_by(issue_deadline_date) %>% 
      summarise(score = n())
  
  df_score_issue_deadline_date_month
}

cum_score_issue_deadline_date_month <- function(df_issue_deadline_date_month) {
  df_score_issue_deadline_date_month <- 
    score_issue_deadline_date_month(df_issue_deadline_date_month)
  
  df_cum_score_issue_deadline_date_month <- 
    df_score_issue_deadline_date_month %>%
      mutate(cumscore = cumsum(score))
  
  df_cum_score_issue_deadline_date_month
}
```

```{r}
plot_cum_score_issue_deadline_date_month <- function(df_issue_deadline_date_month) {
  df_cum_score_issue_deadline_date_month <- 
    cum_score_issue_deadline_date_month(df_issue_deadline_date_month)
  
  plot_cum_score_issue_deadline_date_month <-
    df_cum_score_issue_deadline_date_month %>% 
      ggplot(aes(x = issue_deadline_date, y = cumscore)) +
        geom_area(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        geom_point(color = DEFAULT_COLOR) +
        plot_year_vline() +
        geom_smooth(method = "lm", size = .5, fill = "blue", alpha = .2) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.02, 0)) +
        scale_y_continuous(breaks = seq(0, 1600, 200),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_deadline_date_month),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        coord_cartesian(ylim = c(0, 1600)) +
        labs(title = "Cumulative Number of Issues Deadlines per Month",
             subtitle = subtitle(nrow(df_issue_deadline_date_month)),
             x = "Issue deadline date (month)",
             y = "Number of issues") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1)) 
  
  plot_cum_score_issue_deadline_date_month
}

df_issue_deadline_date_month <- 
  issues %>% 
    filter(!is.na(issue_deadline_date)) %>% 
    distinct(issue_id, 
             issue_deadline_date = as.Date(floor_date(issue_deadline_date,
                                                      "month")))
```

```{r "Cumulative Number of Issues Deadlines per Month"}
plt_cum_score_issue_deadline_date_month <- 
  df_issue_deadline_date_month %>% 
    plot_cum_score_issue_deadline_date_month()

plt_cum_score_issue_deadline_date_month
```

> **Note:** In the plot above, the blue solid line represents the trend of the 
data and dotted grey vertical lines represent the 1st day of year.

Until January of 2017, the growth curve of the cumulative number of issues 
deadlines per month is similiar to the creation and start growth curve. After 
that, a fall happens. Because that, the trend line does not fit well with growth 
curve.

```{r}
plot_score_issue_deadline_date_month <- function(df_issue_deadline_date_month) {
  df_score_issue_deadline_date_month <- 
    score_issue_deadline_date_month(df_issue_deadline_date_month)
    
  plot_score_issue_deadline_date_month <- 
    df_score_issue_deadline_date_month %>% 
      ggplot(aes(x = issue_deadline_date, y = score)) +
        geom_area(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        geom_point(color = DEFAULT_COLOR) +
        plot_year_vline() +
        plot_cumsummary(df_score_issue_deadline_date_month, 
                        x = issue_deadline_date,
                        y = score) +
        scale_x_date(date_breaks = "3 month", date_labels = "%b %Y",
                     expand = c(0.02, 0)) +
        scale_y_continuous(breaks = seq(0, 80, 5)) +
        labs(title = "Distribution of the Number of Issue Deadlines per Month",
             subtitle = subtitle(nrow(df_issue_deadline_date_month)),
             x = "Issue deadline date (per month)",
             y = "Frequency") +
        theme(axis.text.x = element_text(angle = 40, hjust = 1))
  
  plot_score_issue_deadline_date_month
}
```

In the plot below, we can see this behavior in another way.

```{r "Distribution of the Number of Issue Deadlines per Month"}
plt_score_issue_deadline_date_month <- 
  df_issue_deadline_date_month %>% 
    plot_score_issue_deadline_date_month()

plt_score_issue_deadline_date_month
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
accumulated quartile, the black and red solid lines represent, respectivaly, 
accumulated median and mean and dotted grey vertical lines represent the 1st day 
of year.

Note how, after April of 2017, the frequency of issue deadlines decreases and 
does not rise again. The same occur with accumulated summaries. This phenomenon 
did not occur with creation and start date.

The reason for this is lack of data. After April of 2017, the number of issues 
with deadline information decreases. Few issues have planned your delivery date.
This is interesting information for teams to review in order to improve planning 
and control of activities.

```{r}
plot_score_issue_deadline_wday <- function(df_issue_deadline_wday,
                                           subtitle_complement = NULL) {
  summ_issue_deadline_wday <- 
    df_issue_deadline_wday %>% 
      group_by(issue_deadline_wday) %>% 
      summarise(frequency = n()) %>% 
      df_summary(frequency)

  df_score_issue_deadline_wday <- 
    df_issue_deadline_wday %>% 
      group_by(issue_deadline_wday) %>% 
      summarise(score = n())

  plot_score_issue_deadline_wday <- 
    df_score_issue_deadline_wday %>% 
      ggplot(aes(x = issue_deadline_wday, y = score)) +
        geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        plot_y_summary(df_issue_deadline_wday, issue_deadline_wday) +
        scale_y_continuous(breaks = seq(0, 500, 50),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_deadline_wday),
                             breaks = seq(0, 1, .02),
                             labels = scales::percent
                           )) +
        labs(title = "Frequency of Issues Deadline per Weekday",
             subtitle = subtitle(nrow(df_issue_deadline_wday),
                                 subtitle_complement,
                                 summ_issue_deadline_wday),
             x = "Weekday",
             y = "Frequency") 
  
  plot_score_issue_deadline_wday
}

df_issue_deadline_wday <- 
  issues %>% 
    filter(!is.na(issue_deadline_date)) %>% 
    distinct(issue_id, 
             issue_deadline_wday = wday(issue_deadline_date, label = TRUE))
```

As expected, issue deadlines do not occur on Sundays. The deliver was planned to
business days (from Monday to Friday) as we can note in the barplot below.

```{r "Frequency of Issues Deadline per Weekday"}
plt_score_issue_deadline_wday <-
  df_issue_deadline_wday %>% 
    plot_score_issue_deadline_wday()

plt_score_issue_deadline_wday
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean,
and the black dotted lines represents the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

Issues with deadline to weenkend may be considered outliers. These are issues 
created on weekend shift (during the enrollment periods) with deadline size 0 
(day). Removing them, we have a new barplot. See it below.

```{r "Frequency of Issues Deadline per Weekday (No Weekend)"}
plt_score_issue_deadline_wday <- 
  df_issue_deadline_wday %>% 
    filter(issue_deadline_wday != "Sat") %>% 
    plot_score_issue_deadline_wday("without the weekend")

plt_score_issue_deadline_wday
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

Tuesday is the weekday that has more issue deadlines (mode). Monday and Friday 
are the business days with less issue deadline. The reason for this is similar 
to issue creation and start date: from April 2014, the work began to be planned 
by sprints and these sprints were planned every Tuesday morning. The sprints had 
one week duration and, for a time, had two weeks duration. Always starting and 
ending on Tuesdays. It is worth mentioning that not all issues were part of the 
sprint and not all issues in the sprint had deadline of the sprint size.

To analize better this behavior I created a new variable named 
`issue_deadline_size` which represents the total planned time to solve and 
deliver an issue, that is, the difference between issue start and deadline date. 
This variable is interesting because it gives us an idea of the planning of the 
activities.

```{r}
issues$issue_deadline_size <-
  issues %>% 
    select(issue_id, issue_start_date, issue_deadline_date) %>%  
    mutate(issue_deadline_size = difftime(issue_deadline_date,
                                          issue_start_date,
                                          units = "days"))  %>% 
    pull(issue_deadline_size) 
```

### Issue Deadline Size

```{r}
plot_issue_deadline_size <- function(df_issue_deadline_size) {
  summ_issue_deadline_size <- df_summary(df_issue_deadline_size, 
                                         issue_deadline_size)
  
  plot_issue_deadline_size <-
    df_issue_deadline_size %>% 
      ggplot(aes(x = issue_deadline_size)) +
        geom_histogram(binwidth = 1, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                       boundary = summ_issue_deadline_size$min, 
                       closed = "left") +
        plot_x_summary(df_issue_deadline_size, issue_deadline_size) +
        scale_x_continuous(breaks = seq(0, 45, 2)) +
        scale_y_continuous(limits = c(0, 400), breaks = seq(0, 400, 30)) +
        coord_cartesian(xlim = c(0, 45)) +
        labs(title = "Distribution of the Deadline Size",
             subtitle = subtitle(nrow(df_issue_deadline_size),
                                 df_summary = summ_issue_deadline_size),
             x = "Number of calendar days",
             y = "Frequency") 
  
  plot_issue_deadline_size
}

df_issue_deadline_size <-
  issues %>% 
    select(issue_id, issue_deadline_size) %>% 
    filter(!is.na(issue_deadline_size)) %>% 
    filter(issue_deadline_size >= 0)
```

See in the plot below how is the distribution of the deadline size.

```{r "Distribution of the Deadline Size"}
plt_issue_deadline_size <- 
  df_issue_deadline_size %>% 
    plot_issue_deadline_size()

plt_issue_deadline_size
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted line represents upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

Note that the common planning is to solve issues and deliver them within 7 days 
or exactly in 14 days. The most issues are planned to deliver in the same day.
These issues should be easy to resolve or have high priority.

The reason for some issues have 14 days of deadline size is had a period in the 
project that there were two weeks sprints. But this planning was later 
changed to one week sprints.

### Issue Time Spent

```{r}
plot_issue_time_spent_hour <- function(df_issue_time_spent_hour,
                                       binwidth = 1,
                                       complement = NULL,
                                       x.breaks = waiver(),
                                       y.breaks = waiver(),
                                       xlim = NULL,
                                       ylim = NULL,
                                       x.label = NULL) {

  summ_issue_time_spent_hour <- df_summary(df_issue_time_spent_hour, 
                                           issue_time_spent)
  
  plot_issue_time_spent_hour <- 
    df_issue_time_spent_hour %>% 
      ggplot(aes(x = issue_time_spent)) +
        geom_histogram(binwidth = binwidth, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                       boundary = summ_issue_time_spent_hour$min, 
                       closed = "left") +
        plot_x_summary(df_issue_time_spent_hour, issue_time_spent) +
        scale_x_continuous(breaks = x.breaks) +
        scale_y_continuous(breaks = y.breaks) +
        coord_cartesian(xlim = xlim, ylim = ylim) +
        labs(title = "Distribution of the Number of Time Spent on a Issue per Hour",
             subtitle = subtitle(nrow(df_issue_time_spent_hour),
                                 complement,
                                 summ_issue_time_spent_hour),
             x = x.label,
             y = "Frequency") 
  
  plot_issue_time_spent_hour

}

df_issue_time_spent_hour <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, 
             issue_time_spent = (issue_time_spent / 3600))
```

Issue time spent is the total time spent solving the issue. It is a derivation 
of the sum of `log_time_spent`. In the dataset, issue time spent is represented 
in seconds. The plot below shows its distribution per hour.

```{r "Distribution of the Number of Time Spent on a Issue per Hour"}
plt_issue_time_spent_hour <-
  df_issue_time_spent_hour %>% 
    plot_issue_time_spent_hour(x.breaks = seq(0, 110, 5),
                               y.breaks = seq(0, 3000, 250),
                               x.label = "Hours spent")

plt_issue_time_spent_hour
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted line represent the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

Note as the distribution comprises below 5 hours (upper threshold to the 
outliers). The median is 30 minutes (0.5 hour). That is, 50% of time spent is 
less than 30 minutes. Also note that the mean and the 3rd quartile are almost 
the same, approximately 2 hours. This means the dispersion after 5 hours is 
insignicant in relation to the data mass less than 2 hours. Thus, lets zoom in
this plot to first 24 hours. See the result in the plot below.

```{r "Distribution of the Number of Time Spent on a Issue per Hour (Zoomed In)"}
plt_issue_time_spent_24h <-
  df_issue_time_spent_hour %>% 
    plot_issue_time_spent_hour(complement = "zoomed in to the first 24 hours",
                               x.breaks = seq(0, 24, 1),
                               y.breaks = seq(0, 2700, 200),
                               xlim = c(0, 24),
                               x.label = "Hours spent")
plt_issue_time_spent_24h
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted line represent the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

In the plot above, we can see better that time spent on an issue is usually less
than 1 hour. Thus, in the plot below we will analyze it on this scale.

```{r "Distribution of the Number of Time Spent on a Issue (Less Than 1 Hour)"}
df_issue_time_spent_1h <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, issue_time_spent = (issue_time_spent / 60)) %>% 
    filter(issue_time_spent < 60)

plt_issue_time_spent_1h <-
  df_issue_time_spent_1h %>% 
    plot_issue_time_spent_hour(binwidth = 5,
                               complement = "less than 1 hour",
                               x.breaks = seq(0, 60, 5),
                               y.breaks = seq(0, 1500, 150),
                               x.label = "Minutes spent")
plt_issue_time_spent_1h
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted line represent the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

Note that the time spent is spread almost uniformly between 5 and 55 minutes and 
is well concentrated below 5 minutes. To better analyze the range between 0 and 
5 minutes I listed below the first 5 highest frequencies of the number of time 
spent on an issue.

```{r "Head Issue Time Spent"}
df_issue_time_spent_1h %>% 
  group_by(issue_time_spent) %>% 
  summarise(score = sum(!is.na(issue_time_spent))) %>% 
  arrange(desc(score)) %>% 
  head(5) %>% 
  as.data.frame()
```

Note that 1/3 of the issues spend 0 seconds. As there are no `NA` values in this 
variable, we can induce that the default behavior of the tool is to set 0 for 
issues that do not have time spent logged. Removing the 0s we have the following 
distribution.

```{r "Distribution of the Number of Time Spent on a Issue (Less Than 1 Hour and Non 0)"}
df_issue_time_spent_1h_non_0s <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, issue_time_spent = (issue_time_spent / 60)) %>% 
    filter(issue_time_spent != 0 & issue_time_spent < 60)

plt_issue_time_spent_1h_non_0s <-
  df_issue_time_spent_1h_non_0s %>% 
    plot_issue_time_spent_hour(binwidth = 6,
                               complement = "less than 1 hour and non 0 seconds",
                               x.breaks = seq(6, 60, 6),
                               y.breaks = seq(0, 500, 50),
                               x.label = "Minutes spent")

plt_issue_time_spent_1h_non_0s
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

Now, notice that 75% of the issues, with the time spent less than an hour, took 
about 36 minutes to resolve. This time represents about 25% of the time spent 
when analyzing all issues. See this in the plot below that recreates the 
visualization of the time spent on an issue less than 24 hours.

```{r "Distribution of the Number of Time Spent on a Issue (Non 0)"}
df_issue_time_spent_non_0s <- 
  issues %>% 
    filter(!is.na(issue_time_spent)) %>%
    distinct(issue_id, issue_time_spent = (issue_time_spent / 3600)) %>% 
    filter(issue_time_spent != 0)

plt_issue_time_spent_non_0s <-
  df_issue_time_spent_non_0s %>% 
    plot_issue_time_spent_hour(binwidth = 1,
                               complement = "non 0 seconds and zoomed in to the first 24 hours",
                               x.breaks = seq(0, 24, 1),
                               y.breaks = seq(0, 1400, 150),
                               xlim = c(0, 24),
                               x.label = "Hours spent")

plt_issue_time_spent_non_0s
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted line represent the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

Now, the mean and 75% of issues spend more or less 3 hours and 30 minutes to be 
resolved.

### Issue Type

In the issue tracking system, 65 issue types were used to classify the purpose 
of a issue. I grouped them in 4 issue types (see how in 
[issues_cleaning.R](data_wrangling/issues_cleaning.R), lines 54 to 126): 
CUSTOMIZATION, DATA MIGRATION, MAINTENANCE and OTHERS. Their frequencies of 
issues created are shown in the plot below.

```{r}
plot_score_issue_type <- function(df_issue_type,
                                  subtitle_complement = NULL) {
  
  summ_issue_type <- 
    df_issue_type %>% 
      group_by(issue_type) %>% 
      summarise(frequency = n()) %>% 
      df_summary(frequency)
  
  df_score_issue_type <- 
    df_issue_type %>% 
      group_by(issue_type) %>% 
      summarise(score = n())
  
  plot_score_issue_type <- 
    df_score_issue_type %>% 
      ggplot(aes(x = reorder(issue_type, -score), y = score)) +
        geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        plot_y_summary(df_issue_type, issue_type) +
        scale_y_continuous(breaks = seq(0, 3500, 250),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_type),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        labs(title = "Frequency of Issue Type",
             subtitle = subtitle(nrow(df_issue_type),
                                 subtitle_complement,
                                 summ_issue_type),
             x = "Issue type",
             y = "Frequency") 
  
  plot_score_issue_type
}

df_issue_type <- 
  issues %>% 
    filter(!is.na(issue_type)) %>% 
    distinct(issue_id, issue_type)
```

```{r "Frequency of Issue Type"}
plt_score_issue_type <-
  df_issue_type %>% 
    plot_score_issue_type()

plt_score_issue_type
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean.

Analysing the plot above, we note that most of the issues are of the MAINTENANCE 
type (around 75%). Next comes the issues of the CUSTOMIZATION type (around 20%). 
And, around 5% comes the issues of the types DATA MIGRATION and OTHERS. Thus, we 
may summarize that project management was characterized by corrective maintenance 
activities on systems and subsystems.

The demand for adaptation and evolution of the systems was not insignificant. 
Although the amount of CUSTOMIZATION and DATA MIGRATION issues are less than 
MAINTENANCE, they may have indirectly influenced in the creation of large volume 
of MAINTENANCE issues. Maybe, CUSTOMIZATION issues had provocated related creation 
of MAINTENANCE issues. The same is true for DATA MIGRATION. An analysis of 
issue creations timeline by system/subsystem and issue types may answer that 
assumption. See [Issue Creation Date X Issue Subsystem X Issue Type](#issue-creation-date-x-issue-subsystem-x-issue-type) 
section.

### Issue System

On the integrated systems platform ([SIG](https://docs.info.ufrn.br)) there are 
3 main systems: SIGAA (academic), SIPAC (administrative) and SIGRH (human 
resources management). Within these systems, there are many subsystems (modules).
The other systems have purposes of support for these 3 systems or other 
activities.

```{r}
plot_score_issue_system <- function(df_issue_system,
                                    subtitle_complement = NULL) {
  
  summ_issue_system <- 
    df_issue_system %>% 
      group_by(issue_system) %>% 
      summarise(frequency = n()) %>% 
      df_summary(frequency)
  
  df_score_issue_system <- 
    df_issue_system %>% 
      group_by(issue_system) %>% 
      summarise(score = n())
  
  plot_score_issue_system <- 
    df_score_issue_system %>% 
      ggplot(aes(x = reorder(issue_system, -score), y = score)) +
        geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        plot_y_summary(df_issue_system, issue_system) +
        scale_y_continuous(breaks = seq(0, 3500, 250),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_system),
                             breaks = seq(0, 1, .1),
                             labels = scales::percent
                           )) +
        labs(title = "Frequency of Issue System",
             subtitle = subtitle(nrow(df_issue_system),
                                 subtitle_complement,
                                 summ_issue_system),
             x = "Issue system",
             y = "Frequency") +
        theme(axis.text.x = element_text(angle = 20, hjust = 1)) 
  
  plot_score_issue_system
}

df_issue_system <- 
  issues %>% 
    filter(!is.na(issue_system)) %>% 
    distinct(issue_id, issue_system)
```

In the plot below, we may see the frequencies of issues created to 10 systems.

```{r fig.height=4, "Frequency of Issue System"}
plt_score_issue_system <-
  df_issue_system %>% 
    plot_score_issue_system()

plt_score_issue_system
```

> **Note:** In the plot above, the black dashed lines represent the 1st and 3rd 
quartile, the black and red solid lines represent, respectivaly, median and mean
and the black dotted line represent the upper threshold to the outliers 
(3rd qu. + 1.5 IQR).

Note that the academic system, SIGAA, surpasses all other systems together in 
number of created issues. It represents about 75% of all issues created. Also, 
note that, its frequency is considered an outlier (but in practice it is not).
SIPAC (administrative) and SIGRH (human resources management) follow as 2nd and 
3rd position. Both had roughly the same demand. Frequencies of the ohter systems 
are insignificant and we can consider them as outliers.

### Issue Subsystem

```{r}
plot_score_issue_subsystem <- function(df_issue_subsystem,
                                       subtitle_complement = NULL) {
  
  summ_issue_subsystem <- 
    df_issue_subsystem %>% 
      group_by(issue_subsystem) %>% 
      summarise(frequency = n()) %>% 
      df_summary(frequency)
  
  df_score_issue_subsystem <- 
    df_issue_subsystem %>% 
      group_by(issue_subsystem) %>% 
      summarise(score = n())
  
  plot_score_issue_subsystem <- 
    df_score_issue_subsystem %>% 
      ggplot(aes(x = reorder(issue_subsystem, -score), y = score)) +
        geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
        plot_y_summary(df_issue_subsystem, issue_subsystem) +
        scale_y_continuous(breaks = seq(0, 1400, 100),
                           sec.axis = sec_axis(
                             trans = ~. / nrow(df_issue_subsystem),
                             breaks = seq(0, 1, .05),
                             labels = scales::percent
                           )) +
        labs(title = "Frequency (Top 15) of Issue Subsystem",
             subtitle = subtitle(nrow(df_issue_subsystem),
                                 subtitle_complement,
                                 summ_issue_subsystem),
             x = "Issue subsystem",
             y = "Frequency") +
        theme(axis.text.x = element_text(angle = 25, hjust = 1)) 
  
  plot_score_issue_subsystem
}

df_issue_subsystem <- 
  issues %>% 
    filter(!is.na(issue_subsystem)) %>% 
    mutate(issue_subsystem = paste0("(", issue_system, ") ", issue_subsystem)) %>% 
    distinct(issue_id, issue_subsystem)

df_score_top15_issue_subsystem <- 
  df_issue_subsystem %>%
    group_by(issue_subsystem) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) %>% 
    ungroup() %>% 
    filter(row_number() <= 15)
```

```{r fig.height=4.5, "Frequency of Issue Subsystem"}
plt_score_issue_subsystem <-
  df_issue_subsystem %>% 
    filter(issue_subsystem %in% df_score_top15_issue_subsystem$issue_subsystem) %>% 
    plot_score_issue_subsystem()

plt_score_issue_subsystem
```

### Issue Stakeholder

```{r "Frequency of Issue Stakeholder"}
df_issue_stakeholder <-
  issues %>% 
    filter(!is.na(issue_stakeholder)) %>% 
    distinct(issue_id, issue_stakeholder)

df_score_issue_stakeholder <- 
  df_issue_stakeholder %>% 
    group_by(issue_stakeholder) %>% 
    summarise(score = n())

plot_score_issue_stakeholder <- 
  df_score_issue_stakeholder %>% 
    ggplot(aes(x = reorder(issue_stakeholder, -score), y = score)) +
      geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
      # scale_y_continuous(limits = c(0, .85), breaks = seq(0, 1, .1), 
      #                    labels = scales::percent) + 
      labs(title = "Frequency of Issue Stakeholder",
           subtitle = subtitle(nrow(df_issue_stakeholder)),
           x = "Issue stakeholder",
           y = "Frequency") 

plot_score_issue_stakeholder
```

### Issue Created By

```{r "Frequency of Issue Created By"}
df_issue_created_by <-
  issues %>% 
    filter(!is.na(issue_created_by)) %>% 
    mutate(issue_created_by = paste0("(", issue_stakeholder, ") ", 
                                     issue_created_by)) %>% 
    mutate(issue_created_by = first_last_names(issue_created_by)) %>% 
    distinct(issue_id, issue_created_by)

df_score_top15_issue_created_by <- 
  df_issue_created_by %>%
    group_by(issue_created_by) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) %>% 
    ungroup() %>% 
    filter(row_number() <= 15)

plot_score_top15_issue_created_by <- 
  df_score_top15_issue_created_by %>% 
    ggplot(aes(x = reorder(issue_created_by, -score), y = score)) +
      geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
      # scale_y_continuous(limits = c(0, .25), breaks = seq(0, 1, .05), 
      #                    labels = scales::percent) + 
      labs(title = "Frequency (Top 15) of Issue Created By",
           subtitle = subtitle(nrow(df_issue_created_by)),
           x = "Issue created by",
           y = "Frequency") +
      theme(axis.text.x = element_text(angle = 25, hjust = 1)) 

plot_score_top15_issue_created_by
```

### Issue Status

```{r "Frequency of Issue Status"}
df_issue_status <-
  issues %>% 
    filter(!is.na(issue_status)) %>%
    distinct(issue_id, issue_status)

df_score_issue_status <- 
  df_issue_status %>% 
    group_by(issue_status) %>% 
    summarise(score = n())

plot_score_issue_status <- 
  df_score_issue_status %>% 
    ggplot(aes(x = reorder(issue_status, -score), y = score/sum(score))) +
      geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
      add_label(df_score_issue_status$score) +
      scale_y_continuous(limits = c(0, 1.1), breaks = seq(0, 1, .15), 
                         labels = scales::percent) + 
      labs(title = "Frequency of Issue Stakeholder",
           subtitle = subtitle(nrow(df_issue_status)),
           x = "Issue stakeholder",
           y = "Frequency") +
      theme(axis.text.x = element_text(angle = 20, hjust = 1)) 

plot_score_issue_status
```

### Issue Priority Number

```{r "Distribution of the Priority Number per Issue"}
df_issue_priority_number <- 
  issues %>% 
    filter(!is.na(issue_priority_number)) %>%
    distinct(issue_id, issue_priority_number)

summ_issue_priority_number <- df_summary(df_issue_priority_number, 
                                         issue_priority_number)

plot_issue_priority_number <- 
  df_issue_priority_number %>% 
    ggplot(aes(x = issue_priority_number)) +
      geom_histogram(binwidth = 50, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                     boundary = summ_issue_priority_number$min, 
                     closed = "left") +
      plot_x_summary(df_issue_priority_number, issue_priority_number) +
      scale_x_continuous(breaks = seq(0, 999, 50)) +
      scale_y_continuous(breaks = seq(0, 2700, 200)) +
      labs(title = "Distribution of the Priority Number per Issue",
           subtitle = subtitle(nrow(df_issue_priority_number),
                               df_summary = summ_issue_priority_number),
           x = "Issue priority number",
           y = "Frequency")

plot_issue_priority_number
```

```{r "Head Issue Priority Number"}
df_issue_priority_number %>% 
  group_by(issue_priority_number) %>% 
  summarise(score = sum(!is.na(issue_priority_number))) %>% 
  arrange(desc(score)) %>% 
  head(5) %>% 
  as.data.frame()
```

```{r "Distribution of the Priority Number per Issue (Dropped 999 and Zoomed In to 100)"}
df_issue_priority_number <- 
  issues %>% 
    filter(!is.na(issue_priority_number)) %>%
    distinct(issue_id, issue_priority_number) %>% 
    filter(issue_priority_number != 999)

summ_issue_priority_number <- df_summary(df_issue_priority_number, 
                                         issue_priority_number)

plot_issue_priority_number <- 
  df_issue_priority_number %>% 
    ggplot(aes(x = issue_priority_number)) +
      geom_histogram(binwidth = 10, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                     boundary = summ_issue_priority_number$min, 
                     closed = "left") +
      plot_x_summary(df_issue_priority_number, issue_priority_number) +
      scale_x_continuous(breaks = seq(0, 280, 10)) +
      scale_y_continuous(breaks = seq(0, 1600, 150)) +
      coord_cartesian(xlim = c(0, 100)) +
      labs(title = "Distribution of the Priority Number per Issue (Dropped 999)",
           subtitle = subtitle(nrow(df_issue_priority_number),
                               df_summary = summ_issue_priority_number),
           x = "Issue priority number",
           y = "Frequency") 

plot_issue_priority_number
```

```{r "Distribution of the Priority Number per Issue (Less than or Equal to 20)"}
df_issue_priority_number <- 
  issues %>% 
    filter(!is.na(issue_priority_number)) %>%
    distinct(issue_id, issue_priority_number) %>% 
    filter(issue_priority_number <= 20)

summ_issue_priority_number <- df_summary(df_issue_priority_number, 
                                         issue_priority_number)

plot_issue_priority_number <- 
  df_issue_priority_number %>% 
    ggplot(aes(x = issue_priority_number)) +
      geom_histogram(binwidth = 1, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                     boundary = summ_issue_priority_number$min, 
                     closed = "left") +
      plot_x_summary(df_issue_priority_number, issue_priority_number) +
      scale_x_continuous(breaks = seq(0, 20, 1)) +
      scale_y_continuous(breaks = seq(0, 450, 50)) +
      labs(title = "Distribution of the Priority Number per Issue (Less Than or Equal to 20)",
           subtitle = subtitle(nrow(df_issue_priority_number),
                               df_summary = summ_issue_priority_number),
           x = "Issue priority number",
           y = "Frequency") 

plot_issue_priority_number
```

### Issue Priority Scale

```{r "Frequency of Issue Priority Scale"}
df_issue_priority_scale <-
  issues %>% 
    filter(!is.na(issue_priority_scale)) %>%
    distinct(issue_id, issue_priority_scale)

df_score_issue_priority_scale <- 
  df_issue_priority_scale %>% 
    group_by(issue_priority_scale) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score))

plot_score_issue_priority_scale <- 
  df_score_issue_priority_scale %>% 
    ggplot(aes(x = issue_priority_scale, y = score/sum(score))) +
      geom_col(color = DEFAULT_COLOR, alpha = DEFAULT_ALFA) +
      add_label(df_score_issue_priority_scale$score) +
      scale_y_continuous(limits = c(0, .7), breaks = seq(0, 1, .1), 
                         labels = scales::percent) + 
      labs(title = "Frequency of Issue Priority Scale",
           subtitle = subtitle(nrow(df_issue_priority_scale)),
           x = "Issue priority scale",
           y = "Frequency") 

plot_score_issue_priority_scale
```

### Issue Progress

```{r "Distribution of the Progress per Issue"}
df_issue_progress <- 
  issues %>% 
    filter(!is.na(issue_progress)) %>% 
    distinct(issue_id, issue_progress)

summ_issue_progress <- df_summary(df_issue_progress, 
                                  issue_progress)

plot_issue_progress <- 
  df_issue_progress %>% 
    ggplot(aes(x = issue_progress)) +
      geom_histogram(binwidth = 10, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                     boundary = summ_issue_progress$min, 
                     closed = "left") +
      plot_x_summary(df_issue_progress, issue_progress) +
      scale_x_continuous(breaks = seq(0, 100, 10)) +
      scale_y_continuous(breaks = seq(0, 4600, 500)) +
      labs(title = "Distribution of the Progress per Issue",
           subtitle = subtitle(nrow(df_issue_progress),
                               df_summary = summ_issue_progress),
           x = "Issue progress",
           y = "Frequency") 

plot_issue_progress
```

```{r "Head Issue Progress"}
df_issue_progress %>% 
  group_by(issue_progress) %>% 
  summarise(score = sum(!is.na(issue_progress))) %>% 
  arrange(desc(score)) %>% 
  head(5) %>% 
  as.data.frame()
```

### Log Build Info

```{r "Distribution of the Number of the Issues per System's Version"}
df_log_build_info <-
  logs %>% 
    filter(!is.na(log_build_info)) %>% 
    distinct(issue_id, log_build_info) %>% 
    group_by(log_build_info) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) 

summ_log_build_info <- df_summary(df_log_build_info, score)

plot_log_build_info <- 
  df_log_build_info %>% 
    ggplot(aes(x = score)) +
      geom_histogram(binwidth = 5, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                     boundary = summ_log_build_info$min, 
                     closed = "left") +
      plot_x_summary(df_log_build_info, score) +
      scale_x_continuous(breaks = seq(1, 125, 5)) +
      scale_y_continuous(breaks = seq(0, 320, 30)) +
      labs(title = "Distribution of the Number of the Issues per System's Version",
           subtitle = subtitle(nrow(df_log_build_info),
                               df_summary = summ_log_build_info),
           x = "Number of issues",
           y = "Frequency") 

plot_log_build_info
```

```{r "Distribution of the Number of the Issues per System's Version (Less Than 6 Issues)"}
df_log_build_info <- 
  logs %>% 
    filter(!is.na(log_build_info)) %>% 
    distinct(issue_id, log_build_info) %>% 
    group_by(log_build_info) %>% 
    summarise(score = n()) %>% 
    arrange(desc(score)) %>% 
    filter(score < 6)

summ_log_build_info <- df_summary(df_log_build_info, score)

plot_log_build_info <- 
  df_log_build_info %>% 
    ggplot(aes(x = score)) +
      geom_histogram(binwidth = 1, color = DEFAULT_COLOR, alpha = DEFAULT_ALFA, 
                     boundary = summ_log_build_info$min, 
                     closed = "left") +
      plot_x_summary(df_log_build_info, score) +
      scale_x_continuous(breaks = seq(1, 5, 1)) +
      scale_y_continuous(breaks = seq(0, 90, 10)) +
      labs(title = "Distribution of the Number of the Issues per System's Version",
           subtitle = subtitle(nrow(df_log_build_info),
                               df_summary = summ_log_build_info),
           x = "Number of issues",
           y = "Frequency") 

plot_log_build_info
```

### Log Status

> **Go back:** [Data Set Structure](#data-set-structure) 

### Reflections on Data Set Summaries

What is the commom flow of the log states? (Data Set Structure)

What makes the demand low in 2013?
What makes the demand grow rapidly in 2014?

### Association Between Variables

#### Issue Creation Date X Issue Subsystem X Issue Type

An analysis of issue creations timeline by system/subsystem and issue types may 
answer that assumption.