---
output: github_document
---
EDA in an Issue Tracking Data Set
================================================================================
*by Dannyel Cardoso da Fonseca* 

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Cleaning the environment before start
# This is useful when execute "Restart R and Run All Chuncks"
rm(list = ls())
```

```{r echo=FALSE, message=FALSE, warning=FALSE, "Load Packages"}
library(ggplot2)
library(dplyr)
library(lubridate)
library(grid)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, "Set Up"}
# NOTE: To run this notebook set up current work directory to this file location

# Set up default theme for plots
theme_set(theme_classic())
```

```{r echo=FALSE, "Load Data Set"}
# Load the Issues Tracking Data Set
setClass('date_ymd_hms')
setAs("character","date_ymd_hms", function(from) ymd_hms(from))
setClass('date_ymd')
setAs("character", "date_ymd", function(from) ymd(from))
setClass('time_period')
setAs("character", "time_period", function(from) seconds_to_period(from))
setClass('factor_issue_priority_scale')
setAs("character", "factor_issue_priority_scale", 
      function(from) {
        factor(from, levels = c("SUSPENDED",
                                "LOW",
                                "MEDIUM",
                                "HIGH",
                                "URGENT",
                                "BLOCKING"))
      })
issues <- read.csv("issues_tracking.csv", 
                   stringsAsFactors=FALSE, 
                   na.strings = "",
                   colClasses = c("integer", # issue_id
                                  "integer", # issue_number
                                  "character", # issue_title
                                  "factor", # issue_type
                                  "date_ymd_hms", # issue_creation_date
                                  "factor", # issue_system
                                  "date_ymd", # issue_start_date
                                  "factor", # issue_subsystem
                                  "date_ymd", # issue_deadline_date
                                  "character", # issue_created_by
                                  "factor", # issue_stakeholder
                                  "factor", # issue_status
                                  "time_period", # issue_time_spent
                                  "integer", # issue_priority_number
                                  "integer", # issue_progress
                                  "factor_issue_priority_scale",  # issue_priority_scale
                                  "character", # log_build_info
                                  "date_ymd_hms",  # log_creation_date
                                  "factor", # log_action
                                  "factor", # log_status
                                  "integer", # log_progress
                                  "time_period", # log_time_spent
                                  "character", # log_created_by 
                                  "integer" # log_svn_revision 
                                  ))
```

This project aims to explore a data set containing 22,125 observations of issues 
tracking and their history logs. The data set represents 5 years of project 
management which aimed maintenance and customization of many integrated systems
([SIG](https://docs.info.ufrn.br)) for the academic, administrative and human 
resources management at the Universidade Federal de GoiÃ¡s ([UFG](https://www.ufg.br)).

A proprietary issue tracking system ([SIGProject](https://sigproject.esig.com.br)) 
was used to manage activities of teams.

![Screenshot](project_05_files/screenshot-sigproject.esig.com.br-2018.02.25-11-25-48.png)

I used data wrangling techniques to export data from that and clean them. The 
final data set, used in this project, and its documentation can be accessed, 
respectively, in these links: 

- [Issues Data Set](issues_tracking.csv)
- [Issues Data Set Documentation](issues_tracking.Rdoc.txt)

The exported data set, the wrangling process scripts and an example of one issue 
tracking can be find in [data_wrangling](data_wrangling) folder. 

# Data Set Summaries

In this section I perform some preliminary exploration on the data set, analyzing 
its structure and the distributions of some variables.

### Data Set Structure

The issues data set contains 22,125 rows and 24 variables. Of these 24 variables 
16 are about issue data and 8 about issue's logs.

```{r echo=FALSE, message=FALSE, warning=FALSE, "Structure of the Data Set"}
# Show the issues' dataframe structure
str(issues, max.level=1, vec.len=1, nchar.max=50)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
df.summary <- function(df)
{
  data.frame(min = min(df$score), 
               max = max(df$score),
               mean = mean(df$score),
               qu1 = quantile(df$score, probs = .25, names = FALSE),
               median = quantile(df$score, probs = .5, names = FALSE),
               qu3 = quantile(df$score, probs = .75, names = FALSE),
               pc95 = quantile(df$score, probs = .95, names = FALSE),
               iqr = (quantile(df$score, probs = .75, names = FALSE) - 
                      quantile(df$score, probs = .25, names = FALSE)))
}

df.summary.text <- function(df) 
{
  df_summary <- df.summary(df)
  
  paste0("min: ", df_summary$min,
        "    1st qu.: ", df_summary$qu1,
        "    median: ", df_summary$median,
        "    mean: ", round(df_summary$mean,2),
        "    3rd qu.: ", df_summary$qu3,
        "    95 %: ", df_summary$pc95,
        "    max: ", df_summary$max)
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE, "Support Dataframe to Plot (1)"}
# From issues dataframe, it was created another dataframe which counts number of 
# logs per issue_id
df.number_logs_per_issue <- 
  issues %>%
    select(issue_id, log_creation_date) %>%
    group_by(issue_id) %>% 
    summarise(score = sum(!is.na(log_creation_date))) %>% 
    as.data.frame()
```

The number of distinct issues rows and issue's logs rows are 4,503 and 21,978
respectively.

```{r echo=FALSE, message=FALSE, warning=FALSE, "Number of issues and issue's logs"}
data.frame(number_issues = nrow(df.number_logs_per_issue), 
           number_logs = sum(df.number_logs_per_issue$score))
```
We can note that the number of issues represents 20% of the data set and the 
number of logs represents 99% of it. The 1% of logs remaining (147 rows) represents 
issues that do not have history logs. The distribution of number of logs per issue 
and their summaries are presented in the barplot below.

```{r echo=FALSE, fig.retina=2, "Distribution of Number of Logs per Issue"}
# Count number of issues for each number of logs per issue
df.number_logs_per_issue %>%
  group_by(number_logs_per_issue = score) %>%
  summarise(score = n()) %>% 
  as.data.frame() %>% 
  # Output a barplot
  ggplot(aes(x = number_logs_per_issue, y = score)) +
    geom_bar(stat = "identity", alpha = .6) +
    scale_x_continuous(breaks = seq(0, 43, 2)) +
    scale_y_continuous(breaks = seq(0, 800, 50), limits = c(0, 900)) +
    # Summary lines
    geom_vline(data = df.summary(df.number_logs_per_issue),
               mapping = aes(xintercept = mean),
               color = "red", linetype = 1) +
    geom_vline(data = df.summary(df.number_logs_per_issue),
               mapping = aes(xintercept = qu1),
               color = "black", linetype = 3) +
    geom_vline(data = df.summary(df.number_logs_per_issue),
               mapping = aes(xintercept = median),
               color = "black", linetype = 2) +
    geom_vline(data = df.summary(df.number_logs_per_issue),
               mapping = aes(xintercept = qu3),
               color = "black", linetype = 3) +
    geom_vline(data = df.summary(df.number_logs_per_issue),
               mapping = aes(xintercept = qu3 + (iqr * 1.5)),
               color = "gray", linetype = 3) +
    # Labels of summary lines
    geom_text(data = df.summary(df.number_logs_per_issue),
              mapping = aes(x = mean, y = 820, label = "mean"), 
              size = 3, angle = 90, vjust = -.3, hjust = 0, color = "red") +
    geom_text(data = df.summary(df.number_logs_per_issue),
              mapping = aes(x = qu1, y = 820, label = "1st qu."), 
              size = 3, angle = 90, vjust = -.3, hjust = 0) +
    geom_text(data = df.summary(df.number_logs_per_issue),
              mapping = aes(x = median, y = 820, label = "median"), 
              size = 3, angle = 90, vjust = -.3, hjust = 0) +
    geom_text(data = df.summary(df.number_logs_per_issue),
              mapping = aes(x = qu3, y = 820, label = "3rd qu."), 
              size = 3, angle = 90, vjust = -.3, hjust = 0) +
    geom_text(data = df.summary(df.number_logs_per_issue),
              mapping = aes(x = qu3 + (iqr * 1.5), y = 620, label = "upper limit of outliers"), 
              size = 3, angle = 90, vjust = -.3, hjust = 0) +
    labs(title = "Distribution of Number of Logs per Issue",
         subtitle = df.summary.text(df.number_logs_per_issue),
         x = "Number of logs per issue",
         y = "Frequency")
```

Analysing the plot above, we can note that 75% of issues have up to 6 history logs
(before 3rd quartile) and 50% of issues have between 2 and 6 logs (between 1st 
and 3rd quartile). Besides the skewed shape of plot, the median and mean are very 
close. This means that the amount of ouliers, after 12 logs per issue, is low, 
approximately 5% of issues.  

### Issue Creation Date

This data set comprises issues created in the period between 05/21/2013 and 
01/26/2018.

```{r echo=FALSE, message=FALSE, warning=FALSE, "Start and End Issue's Creation Date"}
data.frame(first_issue_creation_date = format(min(issues$issue_creation_date), 
                                              "%m/%d/%Y %H:%M:%S"), 
           last_issue_creation_date = format(max(issues$issue_creation_date), 
                                              "%m/%d/%Y %H:%M:%S"))
```

```{r echo=FALSE, message=FALSE, warning=FALSE, "Support Dataframe to Plot (2)"}
df.issue_creation_date <- 
  issues %>%
    select(issue_id, issue_creation_date) %>%
    group_by(issue_id) %>% 
    summarise(issue_creation_date = first(issue_creation_date)) %>% 
    as.data.frame()

df.number_issues_per_month <- 
  df.issue_creation_date %>%
    group_by(issue_creation_date = as.Date(floor_date(issue_creation_date, "month"))) %>% 
    summarise(score = n()) %>% 
    mutate(cummean = sapply(seq_along(score), 
                            function(x){mean(score[1:x])}),
           cummedian = sapply(seq_along(score), 
                              function(x){median(score[1:x])}),
           cum1stqu = sapply(seq_along(score), 
                             function(x){quantile(score[1:x], probs = .25)}),
           cum3rdqu = sapply(seq_along(score), 
                             function(x){quantile(score[1:x], probs = .75)})) %>% 
    as.data.frame()
```

The distribution of number of issues created by month and the cumulative summaries 
are presented in the barplot below. 

```{r echo=FALSE, fig.retina=2, "Distribution of Number of Issues Created per Month"}
df.number_issues_per_month %>% 
  ggplot(aes(x = issue_creation_date, y = score)) +
    geom_bar(stat = "identity", alpha = .6) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y",
                 limits = c(as.Date("04/01/2013", "%m/%d/%Y"),
                            as.Date("03/01/2018", "%m/%d/%Y"))) +
    scale_y_continuous(breaks = seq(0, 190, 10)) +
    # Summary lines
    geom_line(aes(x = issue_creation_date, y = cummedian), 
              linetype = 2, color = "black") +
    geom_line(aes(x = issue_creation_date, y = cum1stqu), 
              linetype = 3, color = "black") +
    geom_line(aes(x = issue_creation_date, y = cum3rdqu), 
              linetype = 3, color = "black") +
    geom_line(aes(x = issue_creation_date, y = cummean), 
              linetype = 1, color = "red") +
    # Labels of summary lines
    geom_text(data = df.summary(df.number_issues_per_month),
              mapping = aes(x = as.Date("01/01/2018", "%m/%d/%Y"), 
                            y = median, label = "median"), 
              size = 3, vjust = .3, hjust = -.1) +
    geom_text(data = df.summary(df.number_issues_per_month),
              mapping = aes(x = as.Date("01/01/2018", "%m/%d/%Y"), 
                            y = qu1, label = "1st qu."), 
              size = 3, vjust = .3, hjust = -.1) +
    geom_text(data = df.summary(df.number_issues_per_month),
              mapping = aes(x = as.Date("01/01/2018", "%m/%d/%Y"), 
                            y = qu3, label = "3rd qu."), 
              size = 3, vjust = .3, hjust = -.1) +
    geom_text(data = df.summary(df.number_issues_per_month),
              mapping = aes(x = as.Date("01/01/2018", "%m/%d/%Y"), 
                            y = mean, label = "mean"), 
              size = 3, vjust = -.2, hjust = -.1, color = "red") +
    # Rotate axis x
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = "Distribution of Number of Issues Created per Month",
         subtitle = paste("(Overall Summaries)    ", 
                          df.summary.text(df.number_issues_per_month)),
         x = "Issue creation date (per month)",
         y = "Frequency")
  
```

Analysing the plot above, we note that the year 2013 had the lowest demand. The
accumulated mean (red solid line) variates between 10 and 20 issues per month. At 
the end of 2013 and begin of 2014 there was a drop in activities because of the 
low administrative and academic activities at the university in this period. From
April of 2014 until February of 2015 there was significant growth in activities.
The accumulated mean increases from 10 to 70 issues per month. The accumulated mean
overcame the accumulated median and the distance between accumulated 3rd quartile 
and accumulated median became greater than distance between accumulated 1st 
quartile and accumulated median. This means that theses months had a high number 
of issues created in relation to the past. 

But from August of 2015 the pace of growth dropped. Now, we can note that the 
distance between accumulated 1st quartile and accumulated median becomes greater 
than distance between accumulated 3rd quartile and accumulated median. This 
invertion provocated the overlap between accumulated mean and accumulated median. 
The stabilization of growth also contributed to that. The average of growth pass 
to be only 10 monthly issues from February 2015. 

We also note that except the significant growth period (April of 2014 until 
February of 2015) the months from September to December of each year had a 
decline in activities. The reason is the low administrative and academic 
activities at the university in this period. Thus, the demand for the systems 
decreases.

### Issue Type

```{r echo=FALSE, message=FALSE, warning=FALSE, "Issue Type Values"}
levels(issues$issue_type)
```

```{r echo=FALSE, fig.retina=2, "Frequency of Issue Type"}
issues %>%
  group_by(issue_type) %>% 
  summarise(score = n()) %>% 
  ggplot(aes(x = reorder(issue_type, -score), y = score/sum(score))) +
    geom_bar(stat = "identity", alpha = .6) +
    geom_text(aes(label = score), vjust = -1) +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .1)) +
    labs(title = "Frequency of Issue Type",
         x = "Issue type",
         y = "Frequency (relative)")

```

### Reflections on Data Set Summaries

What is the commom flow of the log states?
What makes the demand low in 2013?
What makes the demand grow rapidly in 2014?

```{r echo=FALSE,  message=FALSE, warning=FALSE, "Clean the Environment"}
# rm(list = ls())
```